{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Federated learning implementation on APTOS 2019 Blindness Detection Dataset.\n"
      ],
      "metadata": {
        "id": "t6YVAdU4U6W_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#pip install flwr[simulation]\n",
        "#pip install flwr ray"
      ],
      "metadata": {
        "id": "8_f7cgNOVK_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Extraction"
      ],
      "metadata": {
        "id": "Wv49ry6kWZRQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Create the kaggle.json file with your credentials\n",
        "import json\n",
        "import os\n",
        "\n",
        "# Replace with your Kaggle username and API key\n",
        "kaggle_credentials =xyz,\n",
        "    \"key\": \"xxyzzz\"\n",
        "}\n",
        "\n",
        "# Path to save kaggle.json on Google Drive\n",
        "kaggle_json_path = 'path'\n",
        "\n",
        "# Save the credentials to the kaggle.json file\n",
        "with open(kaggle_json_path, \"w\") as f:\n",
        "    json.dump(kaggle_credentials, f)\n",
        "\n",
        "# Set permissions for the kaggle.json file\n",
        "os.makedirs(\"/root/.kaggle/\", exist_ok=True)\n",
        "!cp {kaggle_json_path} /root/.kaggle/kaggle.json\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "\n",
        "# Verify that the kaggle.json file exists\n",
        "!ls /root/.kaggle/\n",
        "\n",
        "# Directory to save the dataset on Google Drive\n",
        "dataset_path = '/content/drive/MyDrive/aptos2019-blindness-detection'\n",
        "\n",
        "# Create the dataset directory if it doesn't exist\n",
        "os.makedirs(dataset_path, exist_ok=True)\n",
        "\n",
        "# Use Kaggle CLI to download the dataset directly to Google Drive\n",
        "!kaggle competitions download -c aptos2019-blindness-detection -p {dataset_path}\n",
        "\n",
        "# Unzip the dataset\n",
        "!unzip {dataset_path}/aptos2019-blindness-detection.zip -d {dataset_path}\n"
      ],
      "metadata": {
        "id": "MWhQtGbrWYHg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13cskLTp117Q"
      },
      "source": [
        "Resnet"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mobilenet_V2"
      ],
      "metadata": {
        "id": "La2e-hPuSFBT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import OrderedDict\n",
        "from typing import List\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "from torchvision import models\n",
        "import pandas as pd\n",
        "import os\n",
        "import cv2\n",
        "import flwr as fl\n",
        "import ray\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Training on {DEVICE} using PyTorch {torch.__version__} and Flower {fl.__version__}\")\n",
        "NUM_CLIENTS = 10\n",
        "BATCH_SIZE = 32\n",
        "NUM_CLASSES = 5  # Adjust this according to your dataset\n",
        "BEST_MODEL_PATH = '/content/drive/MyDrive/aptos2019-blindness-detection/best_model.pth'\n",
        "\n",
        "# Load data\n",
        "def load_data():\n",
        "    train = pd.read_csv('/content/drive/MyDrive/aptos2019-blindness-detection/train.csv')\n",
        "    test = pd.read_csv('/content/drive/MyDrive/aptos2019-blindness-detection/test.csv')\n",
        "\n",
        "    train_dir = '/content/drive/MyDrive/aptos2019-blindness-detection/train_images'\n",
        "    test_dir = '/content/drive/MyDrive/aptos2019-blindness-detection/test_images'\n",
        "\n",
        "    train['file_path'] = train['id_code'].map(lambda x: os.path.join(train_dir, f'{x}.png'))\n",
        "    test['file_path'] = test['id_code'].map(lambda x: os.path.join(test_dir, f'{x}.png'))\n",
        "\n",
        "    train['diagnosis'] = train['diagnosis'].astype(int)\n",
        "\n",
        "    return train, test\n",
        "\n",
        "df_train, df_test = load_data()\n",
        "print(df_train.shape, df_test.shape, '\\n')\n",
        "df_train.head(6)\n",
        "\n",
        "# Custom Dataset class\n",
        "class APTOSDataset(Dataset):\n",
        "    def __init__(self, dataframe, transform=None):\n",
        "        self.dataframe = dataframe\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.dataframe.iloc[idx]['file_path']\n",
        "        image = cv2.imread(img_path)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        label = self.dataframe.iloc[idx]['diagnosis']\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "# Data transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "])\n",
        "\n",
        "# Create datasets and dataloaders\n",
        "def create_dataloaders(df_train, df_test, num_clients):\n",
        "    # Create a single Dataset object from df_train\n",
        "    full_dataset = APTOSDataset(df_train, transform)\n",
        "\n",
        "    # Calculate the partition size and handle any remainder\n",
        "    dataset_size = len(full_dataset)\n",
        "    partition_size = dataset_size // num_clients\n",
        "    lengths = [partition_size] * num_clients\n",
        "    remainder = dataset_size - sum(lengths)\n",
        "    if remainder > 0:\n",
        "        lengths[-1] += remainder\n",
        "\n",
        "    # Split the dataset into `num_clients` partitions\n",
        "    datasets = random_split(full_dataset, lengths, torch.Generator().manual_seed(42))\n",
        "\n",
        "    # Create dataloaders for each client\n",
        "    trainloaders = []\n",
        "    valloaders = []\n",
        "    for ds in datasets:\n",
        "        len_val = len(ds) // 10  # 10 % validation set\n",
        "        len_train = len(ds) - len_val\n",
        "        lengths = [len_train, len_val]\n",
        "        ds_train, ds_val = random_split(ds, lengths, torch.Generator().manual_seed(42))\n",
        "        trainloader = DataLoader(ds_train, batch_size=BATCH_SIZE, shuffle=True)\n",
        "        valloader = DataLoader(ds_val, batch_size=BATCH_SIZE)\n",
        "        trainloaders.append(trainloader)\n",
        "        valloaders.append(valloader)\n",
        "\n",
        "    testloader = DataLoader(APTOSDataset(df_test, transform), batch_size=BATCH_SIZE)\n",
        "    return trainloaders, valloaders, testloader\n",
        "\n",
        "trainloaders, valloaders, testloader = create_dataloaders(df_train, df_test, NUM_CLIENTS)\n",
        "\n",
        "# Model definition using MobileNetV2\n",
        "def create_mobilenetv2():\n",
        "    model = models.mobilenet_v2(pretrained=True)\n",
        "    model.classifier[1] = nn.Linear(model.last_channel, NUM_CLASSES)\n",
        "    return model.to(DEVICE)\n",
        "\n",
        "# Helper functions for model parameter extraction and loading\n",
        "def get_parameters(net) -> List[np.ndarray]:\n",
        "    return [val.cpu().numpy() for _, val in net.state_dict().items()]\n",
        "\n",
        "def set_parameters(net, parameters: List[np.ndarray]):\n",
        "    params_dict = zip(net.state_dict().keys(), parameters)\n",
        "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
        "    net.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "# Training and evaluation functions\n",
        "def train(net, trainloader, epochs: int):\n",
        "    \"\"\"Train the network on the training set.\"\"\"\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
        "    net.train()\n",
        "    for epoch in range(epochs):\n",
        "        correct, total, epoch_loss = 0, 0, 0.0\n",
        "        for images, labels in trainloader:\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = net(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item()\n",
        "            total += labels.size(0)\n",
        "            correct += (outputs.argmax(1) == labels).sum().item()\n",
        "        epoch_loss /= len(trainloader.dataset)\n",
        "        epoch_acc = correct / total\n",
        "        print(f\"Epoch {epoch+1}: train loss {epoch_loss:.4f}, accuracy {epoch_acc:.4f}\")\n",
        "\n",
        "def test(net, testloader):\n",
        "    \"\"\"Evaluate the network on the entire test set.\"\"\"\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    correct, total, loss = 0, 0, 0.0\n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "        for images, labels in testloader:\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "            outputs = net(images)\n",
        "            loss += criterion(outputs, labels).item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    loss /= len(testloader.dataset)\n",
        "    accuracy = correct / total\n",
        "    return loss, accuracy\n",
        "\n",
        "# Flower client implementation\n",
        "class FlowerClient(fl.client.NumPyClient):\n",
        "    def __init__(self, cid, net, trainloader, valloader):\n",
        "        self.cid = cid\n",
        "        self.net = net\n",
        "        self.trainloader = trainloader\n",
        "        self.valloader = valloader\n",
        "\n",
        "    def get_parameters(self, config):\n",
        "        print(f\"[Client {self.cid}] get_parameters\")\n",
        "        return get_parameters(self.net)\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        print(f\"[Client {self.cid}] fit, config: {config}\")\n",
        "        set_parameters(self.net, parameters)\n",
        "        train(self.net, self.trainloader, epochs=1)\n",
        "        return get_parameters(self.net), len(self.trainloader.dataset), {}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        print(f\"[Client {self.cid}] evaluate, config: {config}\")\n",
        "        set_parameters(self.net, parameters)\n",
        "        loss, accuracy = test(self.net, self.valloader)\n",
        "        return float(loss), len(self.valloader.dataset), {\"accuracy\": float(accuracy)}\n",
        "\n",
        "def client_fn(cid) -> FlowerClient:\n",
        "    net = create_mobilenetv2()\n",
        "    trainloader = trainloaders[int(cid)]\n",
        "    valloader = valloaders[int(cid)]\n",
        "    return FlowerClient(cid, net, trainloader, valloader)\n",
        "\n",
        "# Specify client resources if you need GPU (defaults to 1 CPU and 0 GPU)\n",
        "client_resources = None\n",
        "if DEVICE.type == \"cuda\":\n",
        "    client_resources = {\"num_gpus\": 1}\n",
        "\n",
        "# Start Flower simulation\n",
        "results = fl.simulation.start_simulation(\n",
        "    client_fn=client_fn,\n",
        "    num_clients=NUM_CLIENTS,\n",
        "    config=fl.server.ServerConfig(num_rounds=10),\n",
        "    client_resources=client_resources,\n",
        ")\n",
        "\n",
        "# Extract the final parameters from the simulation results\n",
        "final_parameters = results.parameters\n",
        "\n",
        "# Evaluate the final model and save the best model\n",
        "net = create_mobilenetv2()\n",
        "set_parameters(net, final_parameters)\n",
        "_, final_accuracy = test(net, testloader)\n",
        "torch.save(net.state_dict(), BEST_MODEL_PATH)\n",
        "print(f\"Final Test Accuracy: {final_accuracy:.4f}\")\n",
        "\n",
        "# Plotting accuracy curve\n",
        "accuracy_list = [client['accuracy'] for client in results.client_metrics]\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(range(1, len(accuracy_list) + 1), accuracy_list, marker='o')\n",
        "plt.title('Test Accuracy per Round')\n",
        "plt.xlabel('Round')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yNHWFzIUR9Tg",
        "outputId": "343a23d2-16c7-4510-f51b-e0cbe176bd55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on cpu using PyTorch 2.3.0+cu121 and Flower 1.9.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      Starting Flower simulation, config: num_rounds=10, no round_timeout\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3662, 3) (1928, 2) \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/subprocess.py:1796: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = _posixsubprocess.fork_exec(\n",
            "2024-06-24 08:31:14,738\tINFO worker.py:1752 -- Started a local Ray instance.\n",
            "\u001b[92mINFO \u001b[0m:      Flower VCE: Ray initialized with resources: {'CPU': 8.0, 'object_store_memory': 16339907788.0, 'memory': 32679815579.0, 'node:__internal_head__': 1.0, 'node:172.28.0.12': 1.0}\n",
            "\u001b[92mINFO \u001b[0m:      Optimize your simulation with Flower VCE: https://flower.ai/docs/framework/how-to-run-simulations.html\n",
            "\u001b[92mINFO \u001b[0m:      No `client_resources` specified. Using minimal resources for clients.\n",
            "\u001b[92mINFO \u001b[0m:      Flower VCE: Resources for each Virtual Client: {'num_cpus': 1, 'num_gpus': 0.0}\n",
            "\u001b[92mINFO \u001b[0m:      Flower VCE: Creating VirtualClientEngineActorPool with 8 actors\n",
            "\u001b[92mINFO \u001b[0m:      [INIT]\n",
            "\u001b[92mINFO \u001b[0m:      Requesting initial parameters from one random client\n",
            "\u001b[36m(pid=1849)\u001b[0m 2024-06-24 08:31:16.808944: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(pid=1849)\u001b[0m 2024-06-24 08:31:16.809007: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(pid=1849)\u001b[0m 2024-06-24 08:31:16.810151: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(pid=1852)\u001b[0m 2024-06-24 08:31:18.557055: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[36m(ClientAppActor pid=1854)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "\u001b[36m(ClientAppActor pid=1854)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=1854)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "\u001b[36m(ClientAppActor pid=1854)\u001b[0m   warnings.warn(msg)\n",
            "\u001b[36m(pid=1848)\u001b[0m 2024-06-24 08:31:17.058242: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\u001b[32m [repeated 7x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n",
            "\u001b[36m(pid=1848)\u001b[0m 2024-06-24 08:31:17.058328: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(pid=1848)\u001b[0m 2024-06-24 08:31:17.059569: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1854)\u001b[0m Downloading: \"https://download.pytorch.org/models/mobilenet_v2-b0353104.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v2-b0353104.pth\n",
            "  0%|          | 0.00/13.6M [00:00<?, ?B/s]\n",
            " 27%|██▋       | 3.62M/13.6M [00:00<00:00, 37.8MB/s]\n",
            "\u001b[36m(pid=1848)\u001b[0m 2024-06-24 08:31:18.714846: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "100%|██████████| 13.6M/13.6M [00:00<00:00, 93.4MB/s]\n",
            "\u001b[36m(ClientAppActor pid=1854)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n",
            "\u001b[92mINFO \u001b[0m:      Received initial parameters from one random client\n",
            "\u001b[92mINFO \u001b[0m:      Evaluating initial global parameters\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=1854)\u001b[0m [Client 6] get_parameters\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=1854)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "\u001b[36m(ClientAppActor pid=1854)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=1854)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "\u001b[36m(ClientAppActor pid=1854)\u001b[0m   warnings.warn(msg)\n",
            "\u001b[36m(ClientAppActor pid=1854)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=1854)\u001b[0m [Client 6] fit, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=1853)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "\u001b[36m(ClientAppActor pid=1853)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=1853)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "\u001b[36m(ClientAppActor pid=1853)\u001b[0m   warnings.warn(msg)\n",
            "\u001b[36m(ClientAppActor pid=1853)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n",
            "\u001b[36m(ClientAppActor pid=1851)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "\u001b[36m(ClientAppActor pid=1851)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=1851)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "\u001b[36m(ClientAppActor pid=1851)\u001b[0m   warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=1851)\u001b[0m [Client 5] fit, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=1851)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=1853)\u001b[0m Epoch 1: train loss 0.0296, accuracy 0.6818\n",
            "\u001b[36m(ClientAppActor pid=1846)\u001b[0m [Client 9] fit, config: {}\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=1853)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1853)\u001b[0m   warnings.warn(\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1853)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1853)\u001b[0m   warnings.warn(msg)\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1846)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=1846)\u001b[0m Epoch 1: train loss 0.0278, accuracy 0.6506\n",
            "\u001b[36m(ClientAppActor pid=1853)\u001b[0m [Client 8] fit, config: {}\n",
            "\u001b[36m(ClientAppActor pid=1846)\u001b[0m [Client 2] fit, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=1846)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "\u001b[36m(ClientAppActor pid=1846)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=1846)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "\u001b[36m(ClientAppActor pid=1846)\u001b[0m   warnings.warn(msg)\n",
            "\u001b[36m(ClientAppActor pid=1846)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=1849)\u001b[0m Epoch 1: train loss 0.0307, accuracy 0.6485\n",
            "\u001b[36m(ClientAppActor pid=1848)\u001b[0m Epoch 1: train loss 0.0313, accuracy 0.6333\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1851)\u001b[0m Epoch 1: train loss 0.0290, accuracy 0.6697\n",
            "\u001b[36m(ClientAppActor pid=1852)\u001b[0m Epoch 1: train loss 0.0346, accuracy 0.5758\n",
            "\u001b[36m(ClientAppActor pid=1853)\u001b[0m Epoch 1: train loss 0.0314, accuracy 0.6848\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=1846)\u001b[0m Epoch 1: train loss 0.0312, accuracy 0.6364\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[93mWARNING \u001b[0m:   No fit_metrics_aggregation_fn provided\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 10)\n",
            "\u001b[36m(ClientAppActor pid=1846)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "\u001b[36m(ClientAppActor pid=1846)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=1846)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "\u001b[36m(ClientAppActor pid=1846)\u001b[0m   warnings.warn(msg)\n",
            "\u001b[36m(ClientAppActor pid=1846)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=1853)\u001b[0m [Client 5] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=1853)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1853)\u001b[0m   warnings.warn(\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1853)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1853)\u001b[0m   warnings.warn(msg)\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1849)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=1853)\u001b[0m [Client 6] evaluate, config: {}\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
            "\u001b[93mWARNING \u001b[0m:   No evaluate_metrics_aggregation_fn provided\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n",
            "\u001b[36m(ClientAppActor pid=1849)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1849)\u001b[0m   warnings.warn(\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1849)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1849)\u001b[0m   warnings.warn(msg)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1849)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=1854)\u001b[0m [Client 6] fit, config: {}\n",
            "\u001b[36m(ClientAppActor pid=1849)\u001b[0m [Client 1] evaluate, config: {}\n",
            "\u001b[36m(ClientAppActor pid=1854)\u001b[0m Epoch 1: train loss 0.0329, accuracy 0.6424\n",
            "\u001b[36m(ClientAppActor pid=1848)\u001b[0m [Client 9] fit, config: {}\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=1854)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1854)\u001b[0m   warnings.warn(\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1854)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1854)\u001b[0m   warnings.warn(msg)\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1848)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=1851)\u001b[0m Epoch 1: train loss 0.0284, accuracy 0.6970\n",
            "\u001b[36m(ClientAppActor pid=1854)\u001b[0m [Client 7] fit, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=1851)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "\u001b[36m(ClientAppActor pid=1851)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=1851)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "\u001b[36m(ClientAppActor pid=1851)\u001b[0m   warnings.warn(msg)\n",
            "\u001b[36m(ClientAppActor pid=1854)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n",
            "\u001b[36m(ClientAppActor pid=1851)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=1851)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[36m(ClientAppActor pid=1849)\u001b[0m Epoch 1: train loss 0.0218, accuracy 0.7606\n",
            "\u001b[36m(ClientAppActor pid=1853)\u001b[0m Epoch 1: train loss 0.0288, accuracy 0.7121\n",
            "\u001b[36m(ClientAppActor pid=1848)\u001b[0m Epoch 1: train loss 0.0255, accuracy 0.7169\n",
            "\u001b[36m(ClientAppActor pid=1854)\u001b[0m Epoch 1: train loss 0.0282, accuracy 0.6545\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 10)\n",
            "\u001b[36m(ClientAppActor pid=1850)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "\u001b[36m(ClientAppActor pid=1850)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=1850)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "\u001b[36m(ClientAppActor pid=1850)\u001b[0m   warnings.warn(msg)\n",
            "\u001b[36m(ClientAppActor pid=1850)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=1854)\u001b[0m [Client 4] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=1849)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1849)\u001b[0m   warnings.warn(\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1849)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1849)\u001b[0m   warnings.warn(msg)\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1848)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=1851)\u001b[0m Epoch 1: train loss 0.0235, accuracy 0.7606\n",
            "\u001b[36m(ClientAppActor pid=1849)\u001b[0m [Client 1] evaluate, config: {}\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 3]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n",
            "\u001b[36m(ClientAppActor pid=1849)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1849)\u001b[0m   warnings.warn(\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1849)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1849)\u001b[0m   warnings.warn(msg)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1851)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=1849)\u001b[0m [Client 3] fit, config: {}\n",
            "\u001b[36m(ClientAppActor pid=1851)\u001b[0m [Client 9] evaluate, config: {}\n",
            "\u001b[36m(ClientAppActor pid=1854)\u001b[0m Epoch 1: train loss 0.0238, accuracy 0.7636\n",
            "\u001b[36m(ClientAppActor pid=1853)\u001b[0m [Client 6] fit, config: {}\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=1854)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1854)\u001b[0m   warnings.warn(\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1854)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1854)\u001b[0m   warnings.warn(msg)\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1854)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=1853)\u001b[0m Epoch 1: train loss 0.0281, accuracy 0.7212\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1851)\u001b[0m [Client 2] fit, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1848)\u001b[0m Epoch 1: train loss 0.0315, accuracy 0.7091\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1854)\u001b[0m Epoch 1: train loss 0.0248, accuracy 0.7636\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 10)\n",
            "\u001b[36m(ClientAppActor pid=1851)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1851)\u001b[0m   warnings.warn(\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1851)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1851)\u001b[0m   warnings.warn(msg)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1851)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=1854)\u001b[0m [Client 6] evaluate, config: {}\n",
            "\u001b[36m(ClientAppActor pid=1851)\u001b[0m Epoch 1: train loss 0.0231, accuracy 0.7485\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=1849)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1849)\u001b[0m   warnings.warn(\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1849)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1849)\u001b[0m   warnings.warn(msg)\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1853)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=1849)\u001b[0m [Client 3] evaluate, config: {}\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 4]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n",
            "\u001b[36m(ClientAppActor pid=1852)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1852)\u001b[0m   warnings.warn(\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1852)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1852)\u001b[0m   warnings.warn(msg)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1852)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=1852)\u001b[0m [Client 6] fit, config: {}\n",
            "\u001b[36m(ClientAppActor pid=1852)\u001b[0m [Client 8] evaluate, config: {}\n",
            "\u001b[36m(ClientAppActor pid=1851)\u001b[0m Epoch 1: train loss 0.0215, accuracy 0.7667\n",
            "\u001b[36m(ClientAppActor pid=1848)\u001b[0m [Client 5] fit, config: {}\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=1851)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1851)\u001b[0m   warnings.warn(\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1851)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1851)\u001b[0m   warnings.warn(msg)\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1848)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=1854)\u001b[0m Epoch 1: train loss 0.0240, accuracy 0.7303\n",
            "\u001b[36m(ClientAppActor pid=1854)\u001b[0m [Client 9] fit, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1849)\u001b[0m Epoch 1: train loss 0.0249, accuracy 0.7273\n",
            "\u001b[36m(ClientAppActor pid=1846)\u001b[0m Epoch 1: train loss 0.0212, accuracy 0.7636\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1854)\u001b[0m Epoch 1: train loss 0.0233, accuracy 0.7229\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 10)\n",
            "\u001b[36m(ClientAppActor pid=1851)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1851)\u001b[0m   warnings.warn(\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1851)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1851)\u001b[0m   warnings.warn(msg)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1854)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=1854)\u001b[0m [Client 1] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=1851)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1851)\u001b[0m   warnings.warn(\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1851)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1851)\u001b[0m   warnings.warn(msg)\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1849)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=1851)\u001b[0m Epoch 1: train loss 0.0290, accuracy 0.7000\n",
            "\u001b[36m(ClientAppActor pid=1851)\u001b[0m [Client 3] evaluate, config: {}\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 5]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n",
            "\u001b[36m(ClientAppActor pid=1848)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1848)\u001b[0m   warnings.warn(\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1848)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1848)\u001b[0m   warnings.warn(msg)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1848)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=1848)\u001b[0m [Client 2] fit, config: {}\n",
            "\u001b[36m(ClientAppActor pid=1848)\u001b[0m [Client 5] evaluate, config: {}\n",
            "\u001b[36m(ClientAppActor pid=1854)\u001b[0m Epoch 1: train loss 0.0227, accuracy 0.7199\n",
            "\u001b[36m(ClientAppActor pid=1846)\u001b[0m [Client 5] fit, config: {}\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=1854)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1854)\u001b[0m   warnings.warn(\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1854)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1854)\u001b[0m   warnings.warn(msg)\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1853)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=1849)\u001b[0m Epoch 1: train loss 0.0238, accuracy 0.7303\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1851)\u001b[0m [Client 7] fit, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1848)\u001b[0m Epoch 1: train loss 0.0185, accuracy 0.7909\n",
            "\u001b[36m(ClientAppActor pid=1852)\u001b[0m Epoch 1: train loss 0.0178, accuracy 0.8061\n",
            "\u001b[36m(ClientAppActor pid=1854)\u001b[0m Epoch 1: train loss 0.0185, accuracy 0.8212\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=1851)\u001b[0m Epoch 1: train loss 0.0219, accuracy 0.7515\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=1851)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1851)\u001b[0m   warnings.warn(\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1851)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1851)\u001b[0m   warnings.warn(msg)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1851)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=1851)\u001b[0m [Client 5] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=1853)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1853)\u001b[0m   warnings.warn(\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1853)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1853)\u001b[0m   warnings.warn(msg)\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1849)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=1853)\u001b[0m [Client 3] evaluate, config: {}\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 6]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n",
            "\u001b[36m(ClientAppActor pid=1849)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1849)\u001b[0m   warnings.warn(\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1849)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1849)\u001b[0m   warnings.warn(msg)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1851)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=1853)\u001b[0m [Client 6] fit, config: {}\n",
            "\u001b[36m(ClientAppActor pid=1851)\u001b[0m [Client 1] evaluate, config: {}\n",
            "\u001b[36m(ClientAppActor pid=1854)\u001b[0m Epoch 1: train loss 0.0179, accuracy 0.7879\n",
            "\u001b[36m(ClientAppActor pid=1848)\u001b[0m [Client 9] fit, config: {}\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=1854)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1854)\u001b[0m   warnings.warn(\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1854)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1854)\u001b[0m   warnings.warn(msg)\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1848)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=1849)\u001b[0m Epoch 1: train loss 0.0204, accuracy 0.8333\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1851)\u001b[0m [Client 3] fit, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1852)\u001b[0m Epoch 1: train loss 0.0285, accuracy 0.7242\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1854)\u001b[0m Epoch 1: train loss 0.0181, accuracy 0.7909\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 10)\n",
            "\u001b[36m(ClientAppActor pid=1851)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1851)\u001b[0m   warnings.warn(\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1851)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1851)\u001b[0m   warnings.warn(msg)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1851)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=1851)\u001b[0m [Client 1] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=1854)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1854)\u001b[0m   warnings.warn(\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1854)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1854)\u001b[0m   warnings.warn(msg)\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1849)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=1851)\u001b[0m Epoch 1: train loss 0.0186, accuracy 0.7818\n",
            "\u001b[36m(ClientAppActor pid=1854)\u001b[0m [Client 5] evaluate, config: {}\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 7]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n",
            "\u001b[36m(ClientAppActor pid=1853)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1853)\u001b[0m   warnings.warn(\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1853)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1853)\u001b[0m   warnings.warn(msg)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1853)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=1853)\u001b[0m [Client 6] fit, config: {}\n",
            "\u001b[36m(ClientAppActor pid=1853)\u001b[0m [Client 7] evaluate, config: {}\n",
            "\u001b[36m(ClientAppActor pid=1854)\u001b[0m Epoch 1: train loss 0.0156, accuracy 0.8091\n",
            "\u001b[36m(ClientAppActor pid=1848)\u001b[0m [Client 4] fit, config: {}\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=1854)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1854)\u001b[0m   warnings.warn(\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1854)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1854)\u001b[0m   warnings.warn(msg)\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1850)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=1850)\u001b[0m Epoch 1: train loss 0.0167, accuracy 0.8121\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1851)\u001b[0m [Client 7] fit, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1846)\u001b[0m Epoch 1: train loss 0.0209, accuracy 0.7818\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1854)\u001b[0m Epoch 1: train loss 0.0162, accuracy 0.7970\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=1851)\u001b[0m Epoch 1: train loss 0.0191, accuracy 0.7758\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 10)\n",
            "\u001b[36m(ClientAppActor pid=1851)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1851)\u001b[0m   warnings.warn(\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1851)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1851)\u001b[0m   warnings.warn(msg)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1851)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=1854)\u001b[0m [Client 1] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=1852)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1852)\u001b[0m   warnings.warn(\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1852)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1852)\u001b[0m   warnings.warn(msg)\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1850)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=1852)\u001b[0m [Client 4] evaluate, config: {}\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 8]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n",
            "\u001b[36m(ClientAppActor pid=1852)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1852)\u001b[0m   warnings.warn(\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1852)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1852)\u001b[0m   warnings.warn(msg)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1850)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=1852)\u001b[0m [Client 3] fit, config: {}\n",
            "\u001b[36m(ClientAppActor pid=1850)\u001b[0m [Client 3] evaluate, config: {}\n",
            "\u001b[36m(ClientAppActor pid=1854)\u001b[0m Epoch 1: train loss 0.0212, accuracy 0.7758\n",
            "\u001b[36m(ClientAppActor pid=1849)\u001b[0m [Client 2] fit, config: {}\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=1854)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1854)\u001b[0m   warnings.warn(\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1854)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1854)\u001b[0m   warnings.warn(msg)\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1853)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=1851)\u001b[0m Epoch 1: train loss 0.0191, accuracy 0.7741\n",
            "\u001b[36m(ClientAppActor pid=1854)\u001b[0m [Client 1] fit, config: {}\n",
            "\u001b[36m(ClientAppActor pid=1851)\u001b[0m [Client 7] fit, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=1851)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "\u001b[36m(ClientAppActor pid=1851)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=1851)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "\u001b[36m(ClientAppActor pid=1851)\u001b[0m   warnings.warn(msg)\n",
            "\u001b[36m(ClientAppActor pid=1854)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n",
            "\u001b[36m(ClientAppActor pid=1851)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=1853)\u001b[0m Epoch 1: train loss 0.0215, accuracy 0.7788\n",
            "\u001b[36m(ClientAppActor pid=1850)\u001b[0m Epoch 1: train loss 0.0176, accuracy 0.8242\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1854)\u001b[0m Epoch 1: train loss 0.0209, accuracy 0.7848\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=1851)\u001b[0m Epoch 1: train loss 0.0159, accuracy 0.8394\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 10)\n",
            "\u001b[36m(ClientAppActor pid=1846)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "\u001b[36m(ClientAppActor pid=1846)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=1846)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "\u001b[36m(ClientAppActor pid=1846)\u001b[0m   warnings.warn(msg)\n",
            "\u001b[36m(ClientAppActor pid=1851)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=1854)\u001b[0m [Client 8] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=1852)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1852)\u001b[0m   warnings.warn(\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1852)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1852)\u001b[0m   warnings.warn(msg)\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1846)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=1852)\u001b[0m [Client 9] evaluate, config: {}\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 9]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n",
            "\u001b[36m(ClientAppActor pid=1852)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1852)\u001b[0m   warnings.warn(\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1852)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1852)\u001b[0m   warnings.warn(msg)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1853)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=1852)\u001b[0m [Client 3] fit, config: {}\n",
            "\u001b[36m(ClientAppActor pid=1853)\u001b[0m [Client 3] evaluate, config: {}\n",
            "\u001b[36m(ClientAppActor pid=1851)\u001b[0m Epoch 1: train loss 0.0202, accuracy 0.8030\n",
            "\u001b[36m(ClientAppActor pid=1846)\u001b[0m [Client 4] fit, config: {}\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=1851)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1851)\u001b[0m   warnings.warn(\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1851)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1851)\u001b[0m   warnings.warn(msg)\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1849)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=1848)\u001b[0m Epoch 1: train loss 0.0161, accuracy 0.8333\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1854)\u001b[0m [Client 9] fit, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1852)\u001b[0m Epoch 1: train loss 0.0179, accuracy 0.8121\n",
            "\u001b[36m(ClientAppActor pid=1853)\u001b[0m Epoch 1: train loss 0.0208, accuracy 0.8000\n",
            "\u001b[36m(ClientAppActor pid=1854)\u001b[0m Epoch 1: train loss 0.0141, accuracy 0.8163\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 10)\n",
            "\u001b[36m(ClientAppActor pid=1850)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1850)\u001b[0m   warnings.warn(\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1850)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1850)\u001b[0m   warnings.warn(msg)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1854)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=1854)\u001b[0m [Client 7] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=1849)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1849)\u001b[0m   warnings.warn(\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1849)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1849)\u001b[0m   warnings.warn(msg)\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1848)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=1851)\u001b[0m Epoch 1: train loss 0.0197, accuracy 0.8152\n",
            "\u001b[36m(ClientAppActor pid=1853)\u001b[0m [Client 1] evaluate, config: {}\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 10]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n",
            "\u001b[36m(ClientAppActor pid=1852)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1852)\u001b[0m   warnings.warn(\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1852)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1852)\u001b[0m   warnings.warn(msg)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1853)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=1852)\u001b[0m [Client 5] fit, config: {}\n",
            "\u001b[36m(ClientAppActor pid=1849)\u001b[0m [Client 8] evaluate, config: {}\n",
            "\u001b[36m(ClientAppActor pid=1854)\u001b[0m Epoch 1: train loss 0.0187, accuracy 0.8091\n",
            "\u001b[36m(ClientAppActor pid=1850)\u001b[0m [Client 4] fit, config: {}\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=1854)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1854)\u001b[0m   warnings.warn(\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1854)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1854)\u001b[0m   warnings.warn(msg)\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1854)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=1849)\u001b[0m Epoch 1: train loss 0.0183, accuracy 0.8273\n",
            "\u001b[36m(ClientAppActor pid=1854)\u001b[0m [Client 7] fit, config: {}\n",
            "\u001b[36m(ClientAppActor pid=1851)\u001b[0m Epoch 1: train loss 0.0165, accuracy 0.8121\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=1849)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "\u001b[36m(ClientAppActor pid=1849)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=1849)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "\u001b[36m(ClientAppActor pid=1849)\u001b[0m   warnings.warn(msg)\n",
            "\u001b[36m(ClientAppActor pid=1854)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n",
            "\u001b[36m(ClientAppActor pid=1849)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=1849)\u001b[0m [Client 9] fit, config: {}\n",
            "\u001b[36m(ClientAppActor pid=1850)\u001b[0m Epoch 1: train loss 0.0189, accuracy 0.8030\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1854)\u001b[0m Epoch 1: train loss 0.0202, accuracy 0.7848\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=1849)\u001b[0m Epoch 1: train loss 0.0186, accuracy 0.8072\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 10)\n",
            "\u001b[36m(ClientAppActor pid=1846)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "\u001b[36m(ClientAppActor pid=1846)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=1846)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "\u001b[36m(ClientAppActor pid=1846)\u001b[0m   warnings.warn(msg)\n",
            "\u001b[36m(ClientAppActor pid=1846)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=1854)\u001b[0m [Client 2] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=1849)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1849)\u001b[0m   warnings.warn(\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1849)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1849)\u001b[0m   warnings.warn(msg)\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=1848)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=1854)\u001b[0m [Client 9] evaluate, config: {}\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [SUMMARY]\n",
            "\u001b[92mINFO \u001b[0m:      Run finished 10 round(s) in 2869.93s\n",
            "\u001b[92mINFO \u001b[0m:      \tHistory (loss, distributed):\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 1: 0.06615336934725444\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 2: 0.036889012613230285\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 3: 0.039395290695958665\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 4: 0.04096006786243783\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 5: 0.03933790961487426\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 6: 0.040691786507765455\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 7: 0.0383206677933534\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 8: 0.03930400235371457\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 9: 0.04224831648170948\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 10: 0.04028877524865998\n",
            "\u001b[92mINFO \u001b[0m:      \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'History' object has no attribute 'parameters'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-ce9ec9262b7b>\u001b[0m in \u001b[0;36m<cell line: 201>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;31m# Extract the final parameters from the simulation results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m \u001b[0mfinal_parameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;31m# Evaluate the final model and save the best model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'History' object has no attribute 'parameters'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import OrderedDict\n",
        "from typing import List\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "from torchvision import models\n",
        "import pandas as pd\n",
        "import os\n",
        "import cv2\n",
        "import flwr as fl\n",
        "import ray\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Training on {DEVICE} using PyTorch {torch.__version__} and Flower {fl.__version__}\")\n",
        "NUM_CLIENTS = 4\n",
        "BATCH_SIZE = 64\n",
        "NUM_CLASSES = 5  # Adjust this according to your dataset\n",
        "BEST_MODEL_PATH = '/content/drive/MyDrive/aptos2019-blindness-detection/best_model.pth'\n",
        "\n",
        "# Load data\n",
        "def load_data():\n",
        "    train = pd.read_csv('/content/drive/MyDrive/aptos2019-blindness-detection/train.csv')\n",
        "    test = pd.read_csv('/content/drive/MyDrive/aptos2019-blindness-detection/test.csv')\n",
        "\n",
        "    train_dir = '/content/drive/MyDrive/aptos2019-blindness-detection/train_images'\n",
        "    test_dir = '/content/drive/MyDrive/aptos2019-blindness-detection/test_images'\n",
        "\n",
        "    train['file_path'] = train['id_code'].map(lambda x: os.path.join(train_dir, f'{x}.png'))\n",
        "    test['file_path'] = test['id_code'].map(lambda x: os.path.join(test_dir, f'{x}.png'))\n",
        "\n",
        "    train['diagnosis'] = train['diagnosis'].astype(int)\n",
        "\n",
        "    return train, test\n",
        "\n",
        "df_train, df_test = load_data()\n",
        "print(df_train.shape, df_test.shape, '\\n')\n",
        "df_train.head(6)\n",
        "\n",
        "# Custom Dataset class\n",
        "class APTOSDataset(Dataset):\n",
        "    def __init__(self, dataframe, transform=None):\n",
        "        self.dataframe = dataframe\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.dataframe.iloc[idx]['file_path']\n",
        "        image = cv2.imread(img_path)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        label = self.dataframe.iloc[idx]['diagnosis']\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "# Data transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "])\n",
        "\n",
        "# Create datasets and dataloaders\n",
        "def create_dataloaders(df_train, df_test, num_clients):\n",
        "    # Create a single Dataset object from df_train\n",
        "    full_dataset = APTOSDataset(df_train, transform)\n",
        "\n",
        "    # Calculate the partition size and handle any remainder\n",
        "    dataset_size = len(full_dataset)\n",
        "    partition_size = dataset_size // num_clients\n",
        "    lengths = [partition_size] * num_clients\n",
        "    remainder = dataset_size - sum(lengths)\n",
        "    if remainder > 0:\n",
        "        lengths[-1] += remainder\n",
        "\n",
        "    # Split the dataset into `num_clients` partitions\n",
        "    datasets = random_split(full_dataset, lengths, torch.Generator().manual_seed(42))\n",
        "\n",
        "    # Create dataloaders for each client\n",
        "    trainloaders = []\n",
        "    valloaders = []\n",
        "    for ds in datasets:\n",
        "        len_val = len(ds) // 10  # 10 % validation set\n",
        "        len_train = len(ds) - len_val\n",
        "        lengths = [len_train, len_val]\n",
        "        ds_train, ds_val = random_split(ds, lengths, torch.Generator().manual_seed(42))\n",
        "        trainloader = DataLoader(ds_train, batch_size=BATCH_SIZE, shuffle=True)\n",
        "        valloader = DataLoader(ds_val, batch_size=BATCH_SIZE)\n",
        "        trainloaders.append(trainloader)\n",
        "        valloaders.append(valloader)\n",
        "\n",
        "    testloader = DataLoader(APTOSDataset(df_test, transform), batch_size=BATCH_SIZE)\n",
        "    return trainloaders, valloaders, testloader\n",
        "\n",
        "trainloaders, valloaders, testloader = create_dataloaders(df_train, df_test, NUM_CLIENTS)\n",
        "\n",
        "# Model definition using MobileNetV2\n",
        "def create_mobilenetv2():\n",
        "    model = models.mobilenet_v2(pretrained=True)\n",
        "    model.classifier[1] = nn.Linear(model.last_channel, NUM_CLASSES)\n",
        "    return model.to(DEVICE)\n",
        "\n",
        "# Helper functions for model parameter extraction and loading\n",
        "def get_parameters(net) -> List[np.ndarray]:\n",
        "    return [val.cpu().numpy() for _, val in net.state_dict().items()]\n",
        "\n",
        "def set_parameters(net, parameters: List[np.ndarray]):\n",
        "    params_dict = zip(net.state_dict().keys(), parameters)\n",
        "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
        "    net.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "# Training and evaluation functions\n",
        "def train(net, trainloader, epochs: int):\n",
        "    \"\"\"Train the network on the training set.\"\"\"\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
        "    net.train()\n",
        "    for epoch in range(epochs):\n",
        "        correct, total, epoch_loss = 0, 0, 0.0\n",
        "        for images, labels in trainloader:\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = net(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item()\n",
        "            total += labels.size(0)\n",
        "            correct += (outputs.argmax(1) == labels).sum().item()\n",
        "        epoch_loss /= len(trainloader.dataset)\n",
        "        epoch_acc = correct / total\n",
        "        print(f\"Epoch {epoch+1}: train loss {epoch_loss:.4f}, accuracy {epoch_acc:.4f}\")\n",
        "\n",
        "def test(net, testloader):\n",
        "    \"\"\"Evaluate the network on the entire test set.\"\"\"\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    correct, total, loss = 0, 0, 0.0\n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "        for images, labels in testloader:\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "            outputs = net(images)\n",
        "            loss += criterion(outputs, labels).item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    loss /= len(testloader.dataset)\n",
        "    accuracy = correct / total\n",
        "    return loss, accuracy\n",
        "\n",
        "# Flower client implementation\n",
        "class FlowerClient(fl.client.NumPyClient):\n",
        "    def __init__(self, cid, net, trainloader, valloader):\n",
        "        self.cid = cid\n",
        "        self.net = net\n",
        "        self.trainloader = trainloader\n",
        "        self.valloader = valloader\n",
        "\n",
        "    def get_parameters(self, config):\n",
        "        print(f\"[Client {self.cid}] get_parameters\")\n",
        "        return get_parameters(self.net)\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        print(f\"[Client {self.cid}] fit, config: {config}\")\n",
        "        set_parameters(self.net, parameters)\n",
        "        train(self.net, self.trainloader, epochs=1)\n",
        "        return get_parameters(self.net), len(self.trainloader.dataset), {}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        print(f\"[Client {self.cid}] evaluate, config: {config}\")\n",
        "        set_parameters(self.net, parameters)\n",
        "        loss, accuracy = test(self.net, self.valloader)\n",
        "        return float(loss), len(self.valloader.dataset), {\"accuracy\": float(accuracy)}\n",
        "\n",
        "def client_fn(cid) -> fl.client.Client:\n",
        "    net = create_mobilenetv2()\n",
        "    trainloader = trainloaders[int(cid)]\n",
        "    valloader = valloaders[int(cid)]\n",
        "    numpy_client = FlowerClient(cid, net, trainloader, valloader)\n",
        "    return fl.client.NumPyClient.to_client(numpy_client)\n",
        "\n",
        "# Specify client resources if you need GPU (defaults to 1 CPU and 0 GPU)\n",
        "client_resources = None\n",
        "if DEVICE.type == \"cuda\":\n",
        "    client_resources = {\"num_gpus\": 1}\n",
        "\n",
        "# Start Flower simulation\n",
        "results = fl.simulation.start_simulation(\n",
        "    client_fn=client_fn,\n",
        "    num_clients=NUM_CLIENTS,\n",
        "    config=fl.server.ServerConfig(num_rounds=10),\n",
        "    client_resources=client_resources,\n",
        ")\n",
        "\n",
        "# Extract the final parameters from the simulation results\n",
        "final_parameters = results.metrics_centralized[\"parameters\"][-1] if \"parameters\" in results.metrics_centralized else None\n",
        "\n",
        "if final_parameters is not None:\n",
        "    # Evaluate the final model and save the best model\n",
        "    net = create_mobilenetv2()\n",
        "    set_parameters(net, final_parameters)\n",
        "    _, final_accuracy = test(net, testloader)\n",
        "    torch.save(net.state_dict(), BEST_MODEL_PATH)\n",
        "    print(f\"Final Test Accuracy: {final_accuracy:.4f}\")\n",
        "\n",
        "    # Plotting accuracy curve\n",
        "    accuracy_list = [metric[\"accuracy\"] for metric in results.metrics_centralized[\"accuracy\"]]\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(range(1, len(accuracy_list) + 1), accuracy_list, marker='o')\n",
        "    plt.title('Test Accuracy per Round')\n",
        "    plt.xlabel('Round')\n",
        "    plt.ylabel('Accuracy')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTbNV1VH2th1",
        "outputId": "c297524e-7909-489f-e1dd-f9b636000c93"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      Starting Flower simulation, config: num_rounds=10, no round_timeout\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training on cpu using PyTorch 2.3.0+cu121 and Flower 1.9.0\n",
            "(3662, 3) (1928, 2) \n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/subprocess.py:1796: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = _posixsubprocess.fork_exec(\n",
            "2024-06-24 11:08:24,539\tINFO worker.py:1752 -- Started a local Ray instance.\n",
            "\u001b[92mINFO \u001b[0m:      Flower VCE: Ray initialized with resources: {'object_store_memory': 16340285030.0, 'memory': 32680570062.0, 'node:172.28.0.12': 1.0, 'node:__internal_head__': 1.0, 'CPU': 8.0}\n",
            "\u001b[92mINFO \u001b[0m:      Optimize your simulation with Flower VCE: https://flower.ai/docs/framework/how-to-run-simulations.html\n",
            "\u001b[92mINFO \u001b[0m:      No `client_resources` specified. Using minimal resources for clients.\n",
            "\u001b[92mINFO \u001b[0m:      Flower VCE: Resources for each Virtual Client: {'num_cpus': 1, 'num_gpus': 0.0}\n",
            "\u001b[92mINFO \u001b[0m:      Flower VCE: Creating VirtualClientEngineActorPool with 8 actors\n",
            "\u001b[92mINFO \u001b[0m:      [INIT]\n",
            "\u001b[92mINFO \u001b[0m:      Requesting initial parameters from one random client\n",
            "\u001b[36m(pid=44656)\u001b[0m 2024-06-24 11:08:26.542360: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(pid=44656)\u001b[0m 2024-06-24 11:08:26.542441: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(pid=44656)\u001b[0m 2024-06-24 11:08:26.543878: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(pid=44652)\u001b[0m 2024-06-24 11:08:28.270869: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[36m(ClientAppActor pid=44660)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "\u001b[36m(ClientAppActor pid=44660)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=44660)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "\u001b[36m(ClientAppActor pid=44660)\u001b[0m   warnings.warn(msg)\n",
            "\u001b[36m(pid=44659)\u001b[0m 2024-06-24 11:08:26.908644: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\u001b[32m [repeated 7x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n",
            "\u001b[36m(pid=44659)\u001b[0m 2024-06-24 11:08:26.908721: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(pid=44659)\u001b[0m 2024-06-24 11:08:26.910118: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[92mINFO \u001b[0m:      Received initial parameters from one random client\n",
            "\u001b[92mINFO \u001b[0m:      Evaluating initial global parameters\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n",
            "\u001b[36m(ClientAppActor pid=44660)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "\u001b[36m(ClientAppActor pid=44660)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=44660)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "\u001b[36m(ClientAppActor pid=44660)\u001b[0m   warnings.warn(msg)\n",
            "\u001b[36m(pid=44659)\u001b[0m 2024-06-24 11:08:28.535449: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(ClientAppActor pid=44660)\u001b[0m [Client 0] get_parameters\n",
            "\u001b[36m(ClientAppActor pid=44660)\u001b[0m [Client 2] fit, config: {}\n",
            "\u001b[36m(ClientAppActor pid=44660)\u001b[0m Epoch 1: train loss 0.0135, accuracy 0.6650\n",
            "\u001b[36m(ClientAppActor pid=44657)\u001b[0m [Client 0] fit, config: {}\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=44658)\u001b[0m Epoch 1: train loss 0.0139, accuracy 0.6505\n",
            "\u001b[36m(ClientAppActor pid=44657)\u001b[0m Epoch 1: train loss 0.0124, accuracy 0.7027\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n",
            "\u001b[93mWARNING \u001b[0m:   No fit_metrics_aggregation_fn provided\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 4 clients (out of 4)\n",
            "\u001b[36m(ClientAppActor pid=44659)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=44659)\u001b[0m   warnings.warn(\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=44659)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=44659)\u001b[0m   warnings.warn(msg)\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(ClientAppActor pid=44658)\u001b[0m [Client 0] evaluate, config: {}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 4 results and 0 failures\n",
            "\u001b[93mWARNING \u001b[0m:   No evaluate_metrics_aggregation_fn provided\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n",
            "\u001b[36m(ClientAppActor pid=44658)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=44658)\u001b[0m   warnings.warn(\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=44658)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=44658)\u001b[0m   warnings.warn(msg)\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(ClientAppActor pid=44658)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[36m(ClientAppActor pid=44659)\u001b[0m Epoch 1: train loss 0.0141, accuracy 0.6550\n",
            "\u001b[36m(ClientAppActor pid=44660)\u001b[0m [Client 3] evaluate, config: {}\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=44658)\u001b[0m Epoch 1: train loss 0.0111, accuracy 0.7354\n",
            "\u001b[36m(ClientAppActor pid=44657)\u001b[0m [Client 2] fit, config: {}\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=44657)\u001b[0m Epoch 1: train loss 0.0114, accuracy 0.7391\n",
            "\u001b[36m(ClientAppActor pid=44659)\u001b[0m Epoch 1: train loss 0.0111, accuracy 0.7330\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(ClientAppActor pid=44660)\u001b[0m Epoch 1: train loss 0.0118, accuracy 0.7252\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(ClientAppActor pid=44660)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=44660)\u001b[0m   warnings.warn(\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=44660)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=44660)\u001b[0m   warnings.warn(msg)\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(ClientAppActor pid=44660)\u001b[0m [Client 0] evaluate, config: {}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 4 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 3]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n",
            "\u001b[36m(ClientAppActor pid=44660)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=44660)\u001b[0m   warnings.warn(\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=44660)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=44660)\u001b[0m   warnings.warn(msg)\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(ClientAppActor pid=44660)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[36m(ClientAppActor pid=44658)\u001b[0m [Client 2] evaluate, config: {}\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=44658)\u001b[0m Epoch 1: train loss 0.0100, accuracy 0.7682\n",
            "\u001b[36m(ClientAppActor pid=44659)\u001b[0m [Client 3] fit, config: {}\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=44657)\u001b[0m Epoch 1: train loss 0.0097, accuracy 0.7658\n",
            "\u001b[36m(ClientAppActor pid=44660)\u001b[0m Epoch 1: train loss 0.0091, accuracy 0.8010\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(ClientAppActor pid=44659)\u001b[0m Epoch 1: train loss 0.0109, accuracy 0.7542\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(ClientAppActor pid=44660)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=44660)\u001b[0m   warnings.warn(\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=44660)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=44660)\u001b[0m   warnings.warn(msg)\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(ClientAppActor pid=44660)\u001b[0m [Client 1] evaluate, config: {}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 4 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 4]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n",
            "\u001b[36m(ClientAppActor pid=44657)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=44657)\u001b[0m   warnings.warn(\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=44657)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=44657)\u001b[0m   warnings.warn(msg)\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(ClientAppActor pid=44658)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[36m(ClientAppActor pid=44658)\u001b[0m [Client 2] evaluate, config: {}\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=44658)\u001b[0m Epoch 1: train loss 0.0084, accuracy 0.8083\n",
            "\u001b[36m(ClientAppActor pid=44659)\u001b[0m [Client 3] fit, config: {}\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=44657)\u001b[0m Epoch 1: train loss 0.0094, accuracy 0.7633\n",
            "\u001b[36m(ClientAppActor pid=44660)\u001b[0m Epoch 1: train loss 0.0097, accuracy 0.7803\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 4 clients (out of 4)\n",
            "\u001b[36m(ClientAppActor pid=44659)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=44659)\u001b[0m   warnings.warn(\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=44659)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=44659)\u001b[0m   warnings.warn(msg)\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(ClientAppActor pid=44659)\u001b[0m Epoch 1: train loss 0.0101, accuracy 0.7506\n",
            "\u001b[36m(ClientAppActor pid=44660)\u001b[0m [Client 1] evaluate, config: {}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 4 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 5]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n",
            "\u001b[36m(ClientAppActor pid=44658)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=44658)\u001b[0m   warnings.warn(\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=44658)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=44658)\u001b[0m   warnings.warn(msg)\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(ClientAppActor pid=44660)\u001b[0m [Client 2] fit, config: {}\n",
            "\u001b[36m(ClientAppActor pid=44657)\u001b[0m [Client 3] evaluate, config: {}\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=44658)\u001b[0m Epoch 1: train loss 0.0077, accuracy 0.8192\n",
            "\u001b[36m(ClientAppActor pid=44657)\u001b[0m [Client 3] fit, config: {}\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=44657)\u001b[0m Epoch 1: train loss 0.0080, accuracy 0.8051\n",
            "\u001b[36m(ClientAppActor pid=44660)\u001b[0m Epoch 1: train loss 0.0082, accuracy 0.8058\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 4 clients (out of 4)\n",
            "\u001b[36m(ClientAppActor pid=44660)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=44660)\u001b[0m   warnings.warn(\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=44660)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=44660)\u001b[0m   warnings.warn(msg)\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(ClientAppActor pid=44659)\u001b[0m [Client 3] evaluate, config: {}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 4 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 6]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n",
            "\u001b[36m(ClientAppActor pid=44657)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=44657)\u001b[0m   warnings.warn(\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=44657)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=44657)\u001b[0m   warnings.warn(msg)\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=44660)\u001b[0m [Client 3] fit, config: {}\n",
            "\u001b[36m(ClientAppActor pid=44659)\u001b[0m Epoch 1: train loss 0.0075, accuracy 0.8289\n",
            "\u001b[36m(ClientAppActor pid=44657)\u001b[0m [Client 1] evaluate, config: {}\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=44658)\u001b[0m Epoch 1: train loss 0.0082, accuracy 0.8022\n",
            "\u001b[36m(ClientAppActor pid=44659)\u001b[0m [Client 0] fit, config: {}\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=44657)\u001b[0m Epoch 1: train loss 0.0080, accuracy 0.8010\n",
            "\u001b[36m(ClientAppActor pid=44659)\u001b[0m Epoch 1: train loss 0.0067, accuracy 0.8483\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 4 clients (out of 4)\n",
            "\u001b[36m(ClientAppActor pid=44657)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=44657)\u001b[0m   warnings.warn(\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=44657)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=44657)\u001b[0m   warnings.warn(msg)\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=44660)\u001b[0m [Client 2] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 4 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 7]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n",
            "\u001b[36m(ClientAppActor pid=44657)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=44657)\u001b[0m   warnings.warn(\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=44657)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=44657)\u001b[0m   warnings.warn(msg)\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=44660)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[36m(ClientAppActor pid=44660)\u001b[0m Epoch 1: train loss 0.0089, accuracy 0.7918\n",
            "\u001b[36m(ClientAppActor pid=44658)\u001b[0m [Client 1] evaluate, config: {}\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=44658)\u001b[0m Epoch 1: train loss 0.0074, accuracy 0.8252\n",
            "\u001b[36m(ClientAppActor pid=44659)\u001b[0m [Client 3] fit, config: {}\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=44657)\u001b[0m Epoch 1: train loss 0.0076, accuracy 0.8228\n",
            "\u001b[36m(ClientAppActor pid=44660)\u001b[0m Epoch 1: train loss 0.0071, accuracy 0.8277\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 4 clients (out of 4)\n",
            "\u001b[36m(ClientAppActor pid=44660)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=44660)\u001b[0m   warnings.warn(\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=44660)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=44660)\u001b[0m   warnings.warn(msg)\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=44659)\u001b[0m Epoch 1: train loss 0.0081, accuracy 0.8075\n",
            "\u001b[36m(ClientAppActor pid=44659)\u001b[0m [Client 0] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 4 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 8]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n",
            "\u001b[36m(ClientAppActor pid=44659)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=44659)\u001b[0m   warnings.warn(\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=44659)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=44659)\u001b[0m   warnings.warn(msg)\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=44657)\u001b[0m [Client 2] fit, config: {}\n",
            "\u001b[36m(ClientAppActor pid=44657)\u001b[0m [Client 2] evaluate, config: {}\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=44658)\u001b[0m Epoch 1: train loss 0.0062, accuracy 0.8483\n",
            "\u001b[36m(ClientAppActor pid=44658)\u001b[0m [Client 1] fit, config: {}\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=44657)\u001b[0m Epoch 1: train loss 0.0067, accuracy 0.8374\n",
            "\u001b[36m(ClientAppActor pid=44659)\u001b[0m Epoch 1: train loss 0.0070, accuracy 0.8277\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 4 clients (out of 4)\n",
            "\u001b[36m(ClientAppActor pid=44660)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=44660)\u001b[0m   warnings.warn(\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=44660)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=44660)\u001b[0m   warnings.warn(msg)\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=44659)\u001b[0m [Client 0] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 4 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 9]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n",
            "\u001b[36m(ClientAppActor pid=44659)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=44659)\u001b[0m   warnings.warn(\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=44659)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=44659)\u001b[0m   warnings.warn(msg)\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=44660)\u001b[0m [Client 2] fit, config: {}\n",
            "\u001b[36m(ClientAppActor pid=44660)\u001b[0m Epoch 1: train loss 0.0068, accuracy 0.8269\n",
            "\u001b[36m(ClientAppActor pid=44660)\u001b[0m [Client 3] evaluate, config: {}\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=44658)\u001b[0m Epoch 1: train loss 0.0067, accuracy 0.8426\n",
            "\u001b[36m(ClientAppActor pid=44658)\u001b[0m [Client 3] fit, config: {}\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=44660)\u001b[0m Epoch 1: train loss 0.0062, accuracy 0.8544\n",
            "\u001b[36m(ClientAppActor pid=44657)\u001b[0m Epoch 1: train loss 0.0057, accuracy 0.8532\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 4 clients (out of 4)\n",
            "\u001b[36m(ClientAppActor pid=44659)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=44659)\u001b[0m   warnings.warn(\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=44659)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=44659)\u001b[0m   warnings.warn(msg)\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=44660)\u001b[0m [Client 3] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 4 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 10]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n",
            "\u001b[36m(ClientAppActor pid=44657)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=44657)\u001b[0m   warnings.warn(\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=44657)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=44657)\u001b[0m   warnings.warn(msg)\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=44658)\u001b[0m [Client 1] fit, config: {}\n",
            "\u001b[36m(ClientAppActor pid=44659)\u001b[0m Epoch 1: train loss 0.0065, accuracy 0.8519\n",
            "\u001b[36m(ClientAppActor pid=44659)\u001b[0m [Client 1] evaluate, config: {}\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=44658)\u001b[0m Epoch 1: train loss 0.0052, accuracy 0.8786\n",
            "\u001b[36m(ClientAppActor pid=44660)\u001b[0m [Client 3] fit, config: {}\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=44659)\u001b[0m Epoch 1: train loss 0.0054, accuracy 0.8726\n",
            "\u001b[36m(ClientAppActor pid=44657)\u001b[0m Epoch 1: train loss 0.0054, accuracy 0.8799\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 4 clients (out of 4)\n",
            "\u001b[36m(ClientAppActor pid=44657)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=44657)\u001b[0m   warnings.warn(\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=44657)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=44657)\u001b[0m   warnings.warn(msg)\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=44660)\u001b[0m [Client 3] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 4 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [SUMMARY]\n",
            "\u001b[92mINFO \u001b[0m:      Run finished 10 round(s) in 2290.56s\n",
            "\u001b[92mINFO \u001b[0m:      \tHistory (loss, distributed):\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 1: 0.024228526258861627\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 2: 0.017529774825651566\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 3: 0.014032434139932905\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 4: 0.011900801006909255\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 5: 0.011185917102701061\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 6: 0.013216613126652581\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 7: 0.010013944172597194\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 8: 0.012239336558095702\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 9: 0.015126594639086461\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 10: 0.009813950693869328\n",
            "\u001b[92mINFO \u001b[0m:      \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SqueezNet"
      ],
      "metadata": {
        "id": "YrtPpbzbBqNv"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0wf6x2Estcl"
      },
      "source": [
        "1.1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import OrderedDict\n",
        "from typing import List\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "from torchvision import models\n",
        "import pandas as pd\n",
        "import os\n",
        "import cv2\n",
        "import flwr as fl\n",
        "import ray\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Training on {DEVICE} using PyTorch {torch.__version__} and Flower {fl.__version__}\")\n",
        "NUM_CLIENTS = 4\n",
        "BATCH_SIZE = 64\n",
        "NUM_CLASSES = 5  # Adjust this according to your dataset\n",
        "BEST_MODEL_PATH = '/content/drive/MyDrive/aptos2019-blindness-detection/best_model.pth'\n",
        "\n",
        "# Load data\n",
        "def load_data():\n",
        "    train = pd.read_csv('/content/drive/MyDrive/aptos2019-blindness-detection/train.csv')\n",
        "    test = pd.read_csv('/content/drive/MyDrive/aptos2019-blindness-detection/test.csv')\n",
        "\n",
        "    train_dir = '/content/drive/MyDrive/aptos2019-blindness-detection/train_images'\n",
        "    test_dir = '/content/drive/MyDrive/aptos2019-blindness-detection/test_images'\n",
        "\n",
        "    train['file_path'] = train['id_code'].map(lambda x: os.path.join(train_dir, f'{x}.png'))\n",
        "    test['file_path'] = test['id_code'].map(lambda x: os.path.join(test_dir, f'{x}.png'))\n",
        "\n",
        "    train['diagnosis'] = train['diagnosis'].astype(int)\n",
        "\n",
        "    return train, test\n",
        "\n",
        "df_train, df_test = load_data()\n",
        "print(df_train.shape, df_test.shape, '\\n')\n",
        "df_train.head(6)\n",
        "\n",
        "# Custom Dataset class\n",
        "class APTOSDataset(Dataset):\n",
        "    def __init__(self, dataframe, transform=None):\n",
        "        self.dataframe = dataframe\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.dataframe.iloc[idx]['file_path']\n",
        "        image = cv2.imread(img_path)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        label = self.dataframe.iloc[idx]['diagnosis']\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "# Data transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "])\n",
        "\n",
        "# Create datasets and dataloaders\n",
        "def create_dataloaders(df_train, df_test, num_clients):\n",
        "    # Create a single Dataset object from df_train\n",
        "    full_dataset = APTOSDataset(df_train, transform)\n",
        "\n",
        "    # Calculate the partition size and handle any remainder\n",
        "    dataset_size = len(full_dataset)\n",
        "    partition_size = dataset_size // num_clients\n",
        "    lengths = [partition_size] * num_clients\n",
        "    remainder = dataset_size - sum(lengths)\n",
        "    if remainder > 0:\n",
        "        lengths[-1] += remainder\n",
        "\n",
        "    # Split the dataset into `num_clients` partitions\n",
        "    datasets = random_split(full_dataset, lengths, torch.Generator().manual_seed(42))\n",
        "\n",
        "    # Create dataloaders for each client\n",
        "    trainloaders = []\n",
        "    valloaders = []\n",
        "    for ds in datasets:\n",
        "        len_val = len(ds) // 10  # 10 % validation set\n",
        "        len_train = len(ds) - len_val\n",
        "        lengths = [len_train, len_val]\n",
        "        ds_train, ds_val = random_split(ds, lengths, torch.Generator().manual_seed(42))\n",
        "        trainloader = DataLoader(ds_train, batch_size=BATCH_SIZE, shuffle=True)\n",
        "        valloader = DataLoader(ds_val, batch_size=BATCH_SIZE)\n",
        "        trainloaders.append(trainloader)\n",
        "        valloaders.append(valloader)\n",
        "\n",
        "    testloader = DataLoader(APTOSDataset(df_test, transform), batch_size=BATCH_SIZE)\n",
        "    return trainloaders, valloaders, testloader\n",
        "\n",
        "trainloaders, valloaders, testloader = create_dataloaders(df_train, df_test, NUM_CLIENTS)\n",
        "\n",
        "# Model definition using SqueezeNet\n",
        "def create_squeezenet():\n",
        "    model = models.squeezenet1_1(pretrained=True)\n",
        "    model.classifier[1] = nn.Conv2d(512, NUM_CLASSES, kernel_size=(1,1), stride=(1,1))\n",
        "    model.num_classes = NUM_CLASSES\n",
        "    return model.to(DEVICE)\n",
        "\n",
        "# Helper functions for model parameter extraction and loading\n",
        "def get_parameters(net) -> List[np.ndarray]:\n",
        "    return [val.cpu().numpy() for _, val in net.state_dict().items()]\n",
        "\n",
        "def set_parameters(net, parameters: List[np.ndarray]):\n",
        "    params_dict = zip(net.state_dict().keys(), parameters)\n",
        "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
        "    net.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "# Training and evaluation functions\n",
        "def train(net, trainloader, epochs: int):\n",
        "    \"\"\"Train the network on the training set.\"\"\"\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
        "    net.train()\n",
        "    for epoch in range(epochs):\n",
        "        correct, total, epoch_loss = 0, 0, 0.0\n",
        "        for images, labels in trainloader:\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = net(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item()\n",
        "            total += labels.size(0)\n",
        "            correct += (outputs.argmax(1) == labels).sum().item()\n",
        "        epoch_loss /= len(trainloader.dataset)\n",
        "        epoch_acc = correct / total\n",
        "        print(f\"Epoch {epoch+1}: train loss {epoch_loss:.4f}, accuracy {epoch_acc:.4f}\")\n",
        "\n",
        "def test(net, testloader):\n",
        "    \"\"\"Evaluate the network on the entire test set.\"\"\"\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    correct, total, loss = 0, 0, 0.0\n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "        for images, labels in testloader:\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "            outputs = net(images)\n",
        "            loss += criterion(outputs, labels).item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    loss /= len(testloader.dataset)\n",
        "    accuracy = correct / total\n",
        "    return loss, accuracy\n",
        "\n",
        "# Flower client implementation\n",
        "class FlowerClient(fl.client.NumPyClient):\n",
        "    def __init__(self, cid, net, trainloader, valloader):\n",
        "        self.cid = cid\n",
        "        self.net = net\n",
        "        self.trainloader = trainloader\n",
        "        self.valloader = valloader\n",
        "\n",
        "    def get_parameters(self, config):\n",
        "        print(f\"[Client {self.cid}] get_parameters\")\n",
        "        return get_parameters(self.net)\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        print(f\"[Client {self.cid}] fit, config: {config}\")\n",
        "        set_parameters(self.net, parameters)\n",
        "        train(self.net, self.trainloader, epochs=1)\n",
        "        return get_parameters(self.net), len(self.trainloader.dataset), {}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        print(f\"[Client {self.cid}] evaluate, config: {config}\")\n",
        "        set_parameters(self.net, parameters)\n",
        "        loss, accuracy = test(self.net, self.valloader)\n",
        "        return float(loss), len(self.valloader.dataset), {\"accuracy\": float(accuracy)}\n",
        "\n",
        "def client_fn(cid) -> fl.client.Client:\n",
        "    net = create_squeezenet()\n",
        "    trainloader = trainloaders[int(cid)]\n",
        "    valloader = valloaders[int(cid)]\n",
        "    numpy_client = FlowerClient(cid, net, trainloader, valloader)\n",
        "    return fl.client.NumPyClient.to_client(numpy_client)\n",
        "\n",
        "# Specify client resources if you need GPU (defaults to 1 CPU and 0 GPU)\n",
        "client_resources = None\n",
        "if DEVICE.type == \"cuda\":\n",
        "    client_resources = {\"num_gpus\": 1}\n",
        "\n",
        "# Start Flower simulation\n",
        "results = fl.simulation.start_simulation(\n",
        "    client_fn=client_fn,\n",
        "    num_clients=NUM_CLIENTS,\n",
        "    config=fl.server.ServerConfig(num_rounds=10),\n",
        "    client_resources=client_resources,\n",
        ")\n",
        "\n",
        "# Extract the final parameters from the simulation results\n",
        "final_parameters = results.metrics_centralized[\"parameters\"][-1] if \"parameters\" in results.metrics_centralized else None\n",
        "\n",
        "if final_parameters is not None:\n",
        "    # Evaluate the final model and save the best model\n",
        "    net = create_squeezenet()\n",
        "    set_parameters(net, final_parameters)\n",
        "    _, final_accuracy = test(net, testloader)\n",
        "    torch.save(net.state_dict(), BEST_MODEL_PATH)\n",
        "    print(f\"Final Test Accuracy: {final_accuracy:.4f}\")\n",
        "\n",
        "    # Plotting accuracy curve\n",
        "    accuracy_list = [metric[\"accuracy\"] for metric in results.metrics_centralized[\"accuracy\"]]\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(range(1, len(accuracy_list) + 1), accuracy_list, marker='o')\n",
        "    plt.title('Test Accuracy per Round')\n",
        "    plt.xlabel('Round')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Final parameters could not be extracted from the results.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OyZFGq2-BtDE",
        "outputId": "baa15d52-d47c-4276-90c8-cfb8a763183c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      Starting Flower simulation, config: num_rounds=10, no round_timeout\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on cpu using PyTorch 2.3.0+cu121 and Flower 1.9.0\n",
            "(3662, 3) (1928, 2) \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/subprocess.py:1796: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = _posixsubprocess.fork_exec(\n",
            "2024-06-24 12:26:28,537\tINFO worker.py:1752 -- Started a local Ray instance.\n",
            "\u001b[92mINFO \u001b[0m:      Flower VCE: Ray initialized with resources: {'CPU': 8.0, 'memory': 32709931008.0, 'object_store_memory': 16354965504.0, 'node:__internal_head__': 1.0, 'node:172.28.0.12': 1.0}\n",
            "\u001b[92mINFO \u001b[0m:      Optimize your simulation with Flower VCE: https://flower.ai/docs/framework/how-to-run-simulations.html\n",
            "\u001b[92mINFO \u001b[0m:      No `client_resources` specified. Using minimal resources for clients.\n",
            "\u001b[92mINFO \u001b[0m:      Flower VCE: Resources for each Virtual Client: {'num_cpus': 1, 'num_gpus': 0.0}\n",
            "\u001b[92mINFO \u001b[0m:      Flower VCE: Creating VirtualClientEngineActorPool with 8 actors\n",
            "\u001b[92mINFO \u001b[0m:      [INIT]\n",
            "\u001b[92mINFO \u001b[0m:      Requesting initial parameters from one random client\n",
            "\u001b[36m(pid=65731)\u001b[0m 2024-06-24 12:26:30.765850: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(pid=65731)\u001b[0m 2024-06-24 12:26:30.765917: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(pid=65731)\u001b[0m 2024-06-24 12:26:30.770281: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(pid=65731)\u001b[0m 2024-06-24 12:26:32.505084: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[36m(ClientAppActor pid=65735)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "\u001b[36m(ClientAppActor pid=65735)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=65735)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=SqueezeNet1_1_Weights.IMAGENET1K_V1`. You can also use `weights=SqueezeNet1_1_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "\u001b[36m(ClientAppActor pid=65735)\u001b[0m   warnings.warn(msg)\n",
            "\u001b[36m(pid=65735)\u001b[0m 2024-06-24 12:26:31.032307: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\u001b[32m [repeated 7x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n",
            "\u001b[36m(pid=65735)\u001b[0m 2024-06-24 12:26:31.032368: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(pid=65735)\u001b[0m 2024-06-24 12:26:31.033778: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(pid=65734)\u001b[0m 2024-06-24 12:26:32.724344: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[92mINFO \u001b[0m:      Received initial parameters from one random client\n",
            "\u001b[92mINFO \u001b[0m:      Evaluating initial global parameters\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n",
            "\u001b[36m(ClientAppActor pid=65735)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "\u001b[36m(ClientAppActor pid=65735)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(ClientAppActor pid=65735)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=SqueezeNet1_1_Weights.IMAGENET1K_V1`. You can also use `weights=SqueezeNet1_1_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "\u001b[36m(ClientAppActor pid=65735)\u001b[0m   warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=65735)\u001b[0m [Client 1] get_parameters\n",
            "\u001b[36m(ClientAppActor pid=65735)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[36m(ClientAppActor pid=65735)\u001b[0m Epoch 1: train loss 0.0242, accuracy 0.3944\n",
            "\u001b[36m(ClientAppActor pid=65734)\u001b[0m [Client 1] fit, config: {}\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n",
            "\u001b[93mWARNING \u001b[0m:   No fit_metrics_aggregation_fn provided\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 4 clients (out of 4)\n",
            "\u001b[36m(ClientAppActor pid=65733)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=65733)\u001b[0m   warnings.warn(\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=65733)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=SqueezeNet1_1_Weights.IMAGENET1K_V1`. You can also use `weights=SqueezeNet1_1_Weights.DEFAULT` to get the most up-to-date weights.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=65733)\u001b[0m   warnings.warn(msg)\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=65733)\u001b[0m Epoch 1: train loss 0.0240, accuracy 0.3935\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=65733)\u001b[0m [Client 3] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 4 results and 0 failures\n",
            "\u001b[93mWARNING \u001b[0m:   No evaluate_metrics_aggregation_fn provided\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n",
            "\u001b[36m(ClientAppActor pid=65734)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=65734)\u001b[0m   warnings.warn(\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=65734)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=SqueezeNet1_1_Weights.IMAGENET1K_V1`. You can also use `weights=SqueezeNet1_1_Weights.DEFAULT` to get the most up-to-date weights.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=65734)\u001b[0m   warnings.warn(msg)\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=65733)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[36m(ClientAppActor pid=65735)\u001b[0m [Client 1] evaluate, config: {}\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=65734)\u001b[0m Epoch 1: train loss 0.0202, accuracy 0.5255\n",
            "\u001b[36m(ClientAppActor pid=65735)\u001b[0m [Client 1] fit, config: {}\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 4 clients (out of 4)\n",
            "\u001b[36m(ClientAppActor pid=65732)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=65732)\u001b[0m   warnings.warn(\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=65732)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=SqueezeNet1_1_Weights.IMAGENET1K_V1`. You can also use `weights=SqueezeNet1_1_Weights.DEFAULT` to get the most up-to-date weights.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=65732)\u001b[0m   warnings.warn(msg)\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=65732)\u001b[0m Epoch 1: train loss 0.0203, accuracy 0.5484\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=65733)\u001b[0m [Client 0] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 4 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 3]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n",
            "\u001b[36m(ClientAppActor pid=65732)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=65732)\u001b[0m   warnings.warn(\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=65732)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=SqueezeNet1_1_Weights.IMAGENET1K_V1`. You can also use `weights=SqueezeNet1_1_Weights.DEFAULT` to get the most up-to-date weights.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=65732)\u001b[0m   warnings.warn(msg)\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=65733)\u001b[0m [Client 3] fit, config: {}\n",
            "\u001b[36m(ClientAppActor pid=65734)\u001b[0m [Client 2] evaluate, config: {}\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=65735)\u001b[0m Epoch 1: train loss 0.0248, accuracy 0.4369\n",
            "\u001b[36m(ClientAppActor pid=65735)\u001b[0m [Client 2] fit, config: {}\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 4 clients (out of 4)\n",
            "\u001b[36m(ClientAppActor pid=65732)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=65732)\u001b[0m   warnings.warn(\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=65732)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=SqueezeNet1_1_Weights.IMAGENET1K_V1`. You can also use `weights=SqueezeNet1_1_Weights.DEFAULT` to get the most up-to-date weights.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=65732)\u001b[0m   warnings.warn(msg)\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=65733)\u001b[0m Epoch 1: train loss 0.0198, accuracy 0.5121\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=65733)\u001b[0m [Client 2] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 4 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 4]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n",
            "\u001b[36m(ClientAppActor pid=65732)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=65732)\u001b[0m   warnings.warn(\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=65732)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=SqueezeNet1_1_Weights.IMAGENET1K_V1`. You can also use `weights=SqueezeNet1_1_Weights.DEFAULT` to get the most up-to-date weights.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=65732)\u001b[0m   warnings.warn(msg)\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=65733)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[36m(ClientAppActor pid=65735)\u001b[0m [Client 0] evaluate, config: {}\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=65735)\u001b[0m Epoch 1: train loss 0.0153, accuracy 0.6481\n",
            "\u001b[36m(ClientAppActor pid=65732)\u001b[0m [Client 3] fit, config: {}\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=65733)\u001b[0m Epoch 1: train loss 0.0157, accuracy 0.6578\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 4 clients (out of 4)\n",
            "\u001b[36m(ClientAppActor pid=65732)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=65732)\u001b[0m   warnings.warn(\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=65732)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=SqueezeNet1_1_Weights.IMAGENET1K_V1`. You can also use `weights=SqueezeNet1_1_Weights.DEFAULT` to get the most up-to-date weights.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=65732)\u001b[0m   warnings.warn(msg)\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=65733)\u001b[0m [Client 0] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 4 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 5]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n",
            "\u001b[36m(ClientAppActor pid=65732)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=65732)\u001b[0m   warnings.warn(\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=65732)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=SqueezeNet1_1_Weights.IMAGENET1K_V1`. You can also use `weights=SqueezeNet1_1_Weights.DEFAULT` to get the most up-to-date weights.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=65732)\u001b[0m   warnings.warn(msg)\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=65733)\u001b[0m [Client 3] fit, config: {}\n",
            "\u001b[36m(ClientAppActor pid=65732)\u001b[0m Epoch 1: train loss 0.0160, accuracy 0.6550\n",
            "\u001b[36m(ClientAppActor pid=65735)\u001b[0m [Client 2] evaluate, config: {}\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=65735)\u001b[0m Epoch 1: train loss 0.0187, accuracy 0.6359\n",
            "\u001b[36m(ClientAppActor pid=65735)\u001b[0m [Client 2] fit, config: {}\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 4 clients (out of 4)\n",
            "\u001b[36m(ClientAppActor pid=65732)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=65732)\u001b[0m   warnings.warn(\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=65732)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=SqueezeNet1_1_Weights.IMAGENET1K_V1`. You can also use `weights=SqueezeNet1_1_Weights.DEFAULT` to get the most up-to-date weights.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=65732)\u001b[0m   warnings.warn(msg)\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=65733)\u001b[0m Epoch 1: train loss 0.0155, accuracy 0.6574\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=65733)\u001b[0m [Client 0] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 4 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 6]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n",
            "\u001b[36m(ClientAppActor pid=65733)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=65733)\u001b[0m   warnings.warn(\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=65733)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=SqueezeNet1_1_Weights.IMAGENET1K_V1`. You can also use `weights=SqueezeNet1_1_Weights.DEFAULT` to get the most up-to-date weights.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=65733)\u001b[0m   warnings.warn(msg)\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=65733)\u001b[0m [Client 1] fit, config: {}\n",
            "\u001b[36m(ClientAppActor pid=65735)\u001b[0m [Client 1] evaluate, config: {}\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=65732)\u001b[0m Epoch 1: train loss 0.0166, accuracy 0.6250\n",
            "\u001b[36m(ClientAppActor pid=65735)\u001b[0m [Client 0] fit, config: {}\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=65733)\u001b[0m Epoch 1: train loss 0.0174, accuracy 0.6614\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 4 clients (out of 4)\n",
            "\u001b[36m(ClientAppActor pid=65732)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=65732)\u001b[0m   warnings.warn(\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=65732)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=SqueezeNet1_1_Weights.IMAGENET1K_V1`. You can also use `weights=SqueezeNet1_1_Weights.DEFAULT` to get the most up-to-date weights.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=65732)\u001b[0m   warnings.warn(msg)\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=65734)\u001b[0m [Client 3] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 4 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 7]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n",
            "\u001b[36m(ClientAppActor pid=65732)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=65732)\u001b[0m   warnings.warn(\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=65732)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=SqueezeNet1_1_Weights.IMAGENET1K_V1`. You can also use `weights=SqueezeNet1_1_Weights.DEFAULT` to get the most up-to-date weights.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=65732)\u001b[0m   warnings.warn(msg)\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=65735)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[36m(ClientAppActor pid=65734)\u001b[0m Epoch 1: train loss 0.0160, accuracy 0.6598\n",
            "\u001b[36m(ClientAppActor pid=65735)\u001b[0m [Client 0] evaluate, config: {}\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=65735)\u001b[0m Epoch 1: train loss 0.0138, accuracy 0.6857\n",
            "\u001b[36m(ClientAppActor pid=65734)\u001b[0m [Client 2] fit, config: {}\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 4 clients (out of 4)\n",
            "\u001b[36m(ClientAppActor pid=65732)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=65732)\u001b[0m   warnings.warn(\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=65732)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=SqueezeNet1_1_Weights.IMAGENET1K_V1`. You can also use `weights=SqueezeNet1_1_Weights.DEFAULT` to get the most up-to-date weights.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=65732)\u001b[0m   warnings.warn(msg)\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=65732)\u001b[0m Epoch 1: train loss 0.0143, accuracy 0.6889\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=65732)\u001b[0m [Client 1] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 4 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 8]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n",
            "\u001b[36m(ClientAppActor pid=65734)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=65734)\u001b[0m   warnings.warn(\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=65734)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=SqueezeNet1_1_Weights.IMAGENET1K_V1`. You can also use `weights=SqueezeNet1_1_Weights.DEFAULT` to get the most up-to-date weights.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=65734)\u001b[0m   warnings.warn(msg)\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=65733)\u001b[0m [Client 2] fit, config: {}\n",
            "\u001b[36m(ClientAppActor pid=65735)\u001b[0m [Client 3] evaluate, config: {}\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=65735)\u001b[0m Epoch 1: train loss 0.0146, accuracy 0.7051\n",
            "\u001b[36m(ClientAppActor pid=65735)\u001b[0m [Client 1] fit, config: {}\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 4 clients (out of 4)\n",
            "\u001b[36m(ClientAppActor pid=65732)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=65732)\u001b[0m   warnings.warn(\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=65732)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=SqueezeNet1_1_Weights.IMAGENET1K_V1`. You can also use `weights=SqueezeNet1_1_Weights.DEFAULT` to get the most up-to-date weights.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=65732)\u001b[0m   warnings.warn(msg)\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=65732)\u001b[0m [Client 0] evaluate, config: {}\n",
            "\u001b[36m(ClientAppActor pid=65732)\u001b[0m Epoch 1: train loss 0.0146, accuracy 0.6864\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 4 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 9]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n",
            "\u001b[36m(ClientAppActor pid=65732)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=65732)\u001b[0m   warnings.warn(\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=65732)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=SqueezeNet1_1_Weights.IMAGENET1K_V1`. You can also use `weights=SqueezeNet1_1_Weights.DEFAULT` to get the most up-to-date weights.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=65732)\u001b[0m   warnings.warn(msg)\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=65733)\u001b[0m [Client 3] fit, config: {}\n",
            "\u001b[36m(ClientAppActor pid=65735)\u001b[0m [Client 3] evaluate, config: {}\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=65732)\u001b[0m Epoch 1: train loss 0.0151, accuracy 0.6881\n",
            "\u001b[36m(ClientAppActor pid=65735)\u001b[0m [Client 0] fit, config: {}\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=65733)\u001b[0m Epoch 1: train loss 0.0143, accuracy 0.6925\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=65733)\u001b[0m [Client 2] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=65733)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=65733)\u001b[0m   warnings.warn(\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=65733)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=SqueezeNet1_1_Weights.IMAGENET1K_V1`. You can also use `weights=SqueezeNet1_1_Weights.DEFAULT` to get the most up-to-date weights.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=65733)\u001b[0m   warnings.warn(msg)\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 4 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 10]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n",
            "\u001b[36m(ClientAppActor pid=65732)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=65732)\u001b[0m   warnings.warn(\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=65732)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=SqueezeNet1_1_Weights.IMAGENET1K_V1`. You can also use `weights=SqueezeNet1_1_Weights.DEFAULT` to get the most up-to-date weights.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=65732)\u001b[0m   warnings.warn(msg)\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=65733)\u001b[0m [Client 2] fit, config: {}\n",
            "\u001b[36m(ClientAppActor pid=65735)\u001b[0m [Client 1] evaluate, config: {}\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=65733)\u001b[0m Epoch 1: train loss 0.0140, accuracy 0.7027\n",
            "\u001b[36m(ClientAppActor pid=65735)\u001b[0m [Client 3] fit, config: {}\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 4 clients (out of 4)\n",
            "\u001b[36m(ClientAppActor pid=65732)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=65732)\u001b[0m   warnings.warn(\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=65732)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=SqueezeNet1_1_Weights.IMAGENET1K_V1`. You can also use `weights=SqueezeNet1_1_Weights.DEFAULT` to get the most up-to-date weights.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=65732)\u001b[0m   warnings.warn(msg)\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=65732)\u001b[0m [Client 0] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 4 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [SUMMARY]\n",
            "\u001b[92mINFO \u001b[0m:      Run finished 10 round(s) in 1661.05s\n",
            "\u001b[92mINFO \u001b[0m:      \tHistory (loss, distributed):\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 1: 0.03278468139878996\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 2: 0.02186877239536453\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 3: 0.02538690822465079\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 4: 0.020451713230583694\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 5: 0.023519960242313342\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 6: 0.02110761174788842\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 7: 0.020518485333893326\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 8: 0.020395392244988746\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 9: 0.019378434006984416\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 10: 0.01869435542887384\n",
            "\u001b[92mINFO \u001b[0m:      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final parameters could not be extracted from the results.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import OrderedDict\n",
        "from typing import List\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "from torchvision import models\n",
        "import pandas as pd\n",
        "import os\n",
        "import cv2\n",
        "import flwr as fl\n",
        "import ray\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Training on {DEVICE} using PyTorch {torch.__version__} and Flower {fl.__version__}\")\n",
        "NUM_CLIENTS = 4\n",
        "BATCH_SIZE = 64\n",
        "NUM_CLASSES = 5  # Adjust this according to your dataset\n",
        "BEST_MODEL_PATH = '/content/drive/MyDrive/aptos2019-blindness-detection/best_model.pth'\n",
        "\n",
        "# Load data\n",
        "def load_data():\n",
        "    train = pd.read_csv('/content/drive/MyDrive/aptos2019-blindness-detection/train.csv')\n",
        "    test = pd.read_csv('/content/drive/MyDrive/aptos2019-blindness-detection/test.csv')\n",
        "\n",
        "    train_dir = '/content/drive/MyDrive/aptos2019-blindness-detection/train_images'\n",
        "    test_dir = '/content/drive/MyDrive/aptos2019-blindness-detection/test_images'\n",
        "\n",
        "    train['file_path'] = train['id_code'].map(lambda x: os.path.join(train_dir, f'{x}.png'))\n",
        "    test['file_path'] = test['id_code'].map(lambda x: os.path.join(test_dir, f'{x}.png'))\n",
        "\n",
        "    train['diagnosis'] = train['diagnosis'].astype(int)\n",
        "\n",
        "    return train, test\n",
        "\n",
        "df_train, df_test = load_data()\n",
        "print(df_train.shape, df_test.shape, '\\n')\n",
        "df_train.head(6)\n",
        "\n",
        "# Custom Dataset class\n",
        "class APTOSDataset(Dataset):\n",
        "    def __init__(self, dataframe, transform=None):\n",
        "        self.dataframe = dataframe\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.dataframe.iloc[idx]['file_path']\n",
        "        image = cv2.imread(img_path)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        label = self.dataframe.iloc[idx]['diagnosis']\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "# Data transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "])\n",
        "\n",
        "# Create datasets and dataloaders\n",
        "def create_dataloaders(df_train, df_test, num_clients):\n",
        "    # Create a single Dataset object from df_train\n",
        "    full_dataset = APTOSDataset(df_train, transform)\n",
        "\n",
        "    # Calculate the partition size and handle any remainder\n",
        "    dataset_size = len(full_dataset)\n",
        "    partition_size = dataset_size // num_clients\n",
        "    lengths = [partition_size] * num_clients\n",
        "    remainder = dataset_size - sum(lengths)\n",
        "    if remainder > 0:\n",
        "        lengths[-1] += remainder\n",
        "\n",
        "    # Split the dataset into `num_clients` partitions\n",
        "    datasets = random_split(full_dataset, lengths, torch.Generator().manual_seed(42))\n",
        "\n",
        "    # Create dataloaders for each client\n",
        "    trainloaders = []\n",
        "    valloaders = []\n",
        "    for ds in datasets:\n",
        "        len_val = len(ds) // 10  # 10 % validation set\n",
        "        len_train = len(ds) - len_val\n",
        "        lengths = [len_train, len_val]\n",
        "        ds_train, ds_val = random_split(ds, lengths, torch.Generator().manual_seed(42))\n",
        "        trainloader = DataLoader(ds_train, batch_size=BATCH_SIZE, shuffle=True)\n",
        "        valloader = DataLoader(ds_val, batch_size=BATCH_SIZE)\n",
        "        trainloaders.append(trainloader)\n",
        "        valloaders.append(valloader)\n",
        "\n",
        "    testloader = DataLoader(APTOSDataset(df_test, transform), batch_size=BATCH_SIZE)\n",
        "    return trainloaders, valloaders, testloader\n",
        "\n",
        "trainloaders, valloaders, testloader = create_dataloaders(df_train, df_test, NUM_CLIENTS)\n",
        "\n",
        "# Model definition using ShuffleNetV2\n",
        "def create_shufflenetv2():\n",
        "    model = models.shufflenet_v2_x1_0(weights=models.ShuffleNet_V2_X1_0_Weights.DEFAULT)\n",
        "    model.fc = nn.Linear(model.fc.in_features, NUM_CLASSES)\n",
        "    return model.to(DEVICE)\n",
        "\n",
        "# Helper functions for model parameter extraction and loading\n",
        "def get_parameters(net) -> List[np.ndarray]:\n",
        "    return [val.cpu().numpy() for _, val in net.state_dict().items()]\n",
        "\n",
        "def set_parameters(net, parameters: List[np.ndarray]):\n",
        "    params_dict = zip(net.state_dict().keys(), parameters)\n",
        "    state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n",
        "    net.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "# Training and evaluation functions\n",
        "def train(net, trainloader, epochs: int):\n",
        "    \"\"\"Train the network on the training set.\"\"\"\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
        "    net.train()\n",
        "    for epoch in range(epochs):\n",
        "        correct, total, epoch_loss = 0, 0, 0.0\n",
        "        for images, labels in trainloader:\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = net(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item()\n",
        "            total += labels.size(0)\n",
        "            correct += (outputs.argmax(1) == labels).sum().item()\n",
        "        epoch_loss /= len(trainloader.dataset)\n",
        "        epoch_acc = correct / total\n",
        "        print(f\"Epoch {epoch+1}: train loss {epoch_loss:.4f}, accuracy {epoch_acc:.4f}\")\n",
        "\n",
        "def test(net, testloader):\n",
        "    \"\"\"Evaluate the network on the entire test set.\"\"\"\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    correct, total, loss = 0, 0, 0.0\n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "        for images, labels in testloader:\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "            outputs = net(images)\n",
        "            loss += criterion(outputs, labels).item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    loss /= len(testloader.dataset)\n",
        "    accuracy = correct / total\n",
        "    return loss, accuracy\n",
        "\n",
        "# Flower client implementation\n",
        "class FlowerClient(fl.client.NumPyClient):\n",
        "    def __init__(self, cid, net, trainloader, valloader):\n",
        "        self.cid = cid\n",
        "        self.net = net\n",
        "        self.trainloader = trainloader\n",
        "        self.valloader = valloader\n",
        "\n",
        "    def get_parameters(self, config):\n",
        "        print(f\"[Client {self.cid}] get_parameters\")\n",
        "        return get_parameters(self.net)\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        print(f\"[Client {self.cid}] fit, config: {config}\")\n",
        "        set_parameters(self.net, parameters)\n",
        "        train(self.net, self.trainloader, epochs=1)\n",
        "        return get_parameters(self.net), len(self.trainloader.dataset), {}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        print(f\"[Client {self.cid}] evaluate, config: {config}\")\n",
        "        set_parameters(self.net, parameters)\n",
        "        loss, accuracy = test(self.net, self.valloader)\n",
        "        return float(loss), len(self.valloader.dataset), {\"accuracy\": float(accuracy)}\n",
        "\n",
        "def client_fn(cid) -> fl.client.Client:\n",
        "    net = create_shufflenetv2()\n",
        "    trainloader = trainloaders[int(cid)]\n",
        "    valloader = valloaders[int(cid)]\n",
        "    numpy_client = FlowerClient(cid, net, trainloader, valloader)\n",
        "    return fl.client.NumPyClient.to_client(numpy_client)\n",
        "\n",
        "# Specify client resources if you need GPU (defaults to 1 CPU and 0 GPU)\n",
        "client_resources = None\n",
        "if DEVICE.type == \"cuda\":\n",
        "    client_resources = {\"num_gpus\": 1}\n",
        "\n",
        "# Start Flower simulation\n",
        "results = fl.simulation.start_simulation(\n",
        "    client_fn=client_fn,\n",
        "    num_clients=NUM_CLIENTS,\n",
        "    config=fl.server.ServerConfig(num_rounds=10),\n",
        "    client_resources=client_resources,\n",
        ")\n",
        "\n",
        "# Extract the final parameters from the simulation results\n",
        "final_parameters = results.metrics_centralized[\"parameters\"][-1] if \"parameters\" in results.metrics_centralized else None\n",
        "\n",
        "if final_parameters is not None:\n",
        "    # Evaluate the final model and save the best model\n",
        "    net = create_shufflenetv2()\n",
        "    set_parameters(net, final_parameters)\n",
        "    _, final_accuracy = test(net, testloader)\n",
        "    torch.save(net.state_dict(), BEST_MODEL_PATH)\n",
        "    print(f\"Final Test Accuracy: {final_accuracy:.4f}\")\n",
        "\n",
        "    # Plotting accuracy curve\n",
        "    accuracy_list = [metric[\"accuracy\"] for metric in results.metrics_centralized[\"accuracy\"]]\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(range(1, len(accuracy_list) + 1), accuracy_list, marker='o')\n",
        "    plt.title('Test Accuracy per Round')\n",
        "    plt.xlabel('Round')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Final parameters could not be extracted from the results.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ldkV2L2NcJk",
        "outputId": "3b74a68f-70f7-41f5-9f04-eab30254e575"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      Starting Flower simulation, config: num_rounds=10, no round_timeout\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on cpu using PyTorch 2.3.0+cu121 and Flower 1.9.0\n",
            "(3662, 3) (1928, 2) \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/subprocess.py:1796: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = _posixsubprocess.fork_exec(\n",
            "2024-06-24 13:36:07,043\tINFO worker.py:1752 -- Started a local Ray instance.\n",
            "\u001b[92mINFO \u001b[0m:      Flower VCE: Ray initialized with resources: {'CPU': 8.0, 'object_store_memory': 16348879257.0, 'memory': 32697758516.0, 'node:172.28.0.12': 1.0, 'node:__internal_head__': 1.0}\n",
            "\u001b[92mINFO \u001b[0m:      Optimize your simulation with Flower VCE: https://flower.ai/docs/framework/how-to-run-simulations.html\n",
            "\u001b[92mINFO \u001b[0m:      No `client_resources` specified. Using minimal resources for clients.\n",
            "\u001b[92mINFO \u001b[0m:      Flower VCE: Resources for each Virtual Client: {'num_cpus': 1, 'num_gpus': 0.0}\n",
            "\u001b[92mINFO \u001b[0m:      Flower VCE: Creating VirtualClientEngineActorPool with 8 actors\n",
            "\u001b[92mINFO \u001b[0m:      [INIT]\n",
            "\u001b[92mINFO \u001b[0m:      Requesting initial parameters from one random client\n",
            "\u001b[36m(pid=84642)\u001b[0m 2024-06-24 13:36:08.960504: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(pid=84642)\u001b[0m 2024-06-24 13:36:08.960591: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(pid=84642)\u001b[0m 2024-06-24 13:36:08.962148: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(pid=84642)\u001b[0m 2024-06-24 13:36:10.890993: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[92mINFO \u001b[0m:      Received initial parameters from one random client\n",
            "\u001b[92mINFO \u001b[0m:      Evaluating initial global parameters\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=84645)\u001b[0m [Client 3] get_parameters\n",
            "\u001b[36m(ClientAppActor pid=84645)\u001b[0m [Client 1] fit, config: {}\n",
            "\u001b[36m(ClientAppActor pid=84645)\u001b[0m Epoch 1: train loss 0.0216, accuracy 0.6505\n",
            "\u001b[36m(ClientAppActor pid=84643)\u001b[0m [Client 3] fit, config: {}\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=84643)\u001b[0m Epoch 1: train loss 0.0216, accuracy 0.6102\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[93mWARNING \u001b[0m:   No fit_metrics_aggregation_fn provided\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=84643)\u001b[0m [Client 1] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 4 results and 0 failures\n",
            "\u001b[93mWARNING \u001b[0m:   No evaluate_metrics_aggregation_fn provided\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=84645)\u001b[0m [Client 3] fit, config: {}\n",
            "\u001b[36m(ClientAppActor pid=84645)\u001b[0m [Client 0] evaluate, config: {}\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=84646)\u001b[0m Epoch 1: train loss 0.0144, accuracy 0.7354\n",
            "\u001b[36m(ClientAppActor pid=84643)\u001b[0m [Client 2] fit, config: {}\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=84645)\u001b[0m [Client 1] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 4 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 3]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=84645)\u001b[0m Epoch 1: train loss 0.0153, accuracy 0.7022\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=84645)\u001b[0m [Client 2] fit, config: {}\n",
            "\u001b[36m(ClientAppActor pid=84643)\u001b[0m [Client 0] evaluate, config: {}\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=84644)\u001b[0m [Client 1] fit, config: {}\n",
            "\u001b[36m(ClientAppActor pid=84645)\u001b[0m Epoch 1: train loss 0.0118, accuracy 0.7318\n",
            "\u001b[36m(ClientAppActor pid=84643)\u001b[0m [Client 3] fit, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=84644)\u001b[0m Epoch 1: train loss 0.0113, accuracy 0.7451\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=84643)\u001b[0m Epoch 1: train loss 0.0123, accuracy 0.7179\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=84644)\u001b[0m [Client 1] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 4 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 4]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=84645)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[36m(ClientAppActor pid=84645)\u001b[0m [Client 2] evaluate, config: {}\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=84646)\u001b[0m Epoch 1: train loss 0.0104, accuracy 0.7354\n",
            "\u001b[36m(ClientAppActor pid=84643)\u001b[0m [Client 1] fit, config: {}\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=84644)\u001b[0m Epoch 1: train loss 0.0115, accuracy 0.7252\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=84644)\u001b[0m [Client 2] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 4 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 5]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=84644)\u001b[0m [Client 1] fit, config: {}\n",
            "\u001b[36m(ClientAppActor pid=84643)\u001b[0m [Client 0] evaluate, config: {}\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=84643)\u001b[0m Epoch 1: train loss 0.0098, accuracy 0.7464\n",
            "\u001b[36m(ClientAppActor pid=84646)\u001b[0m [Client 3] fit, config: {}\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=84646)\u001b[0m Epoch 1: train loss 0.0107, accuracy 0.7300\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 4 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 6]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=84646)\u001b[0m [Client 2] evaluate, config: {}\n",
            "\u001b[36m(ClientAppActor pid=84645)\u001b[0m [Client 3] fit, config: {}\n",
            "\u001b[36m(ClientAppActor pid=84643)\u001b[0m [Client 3] evaluate, config: {}\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=84644)\u001b[0m Epoch 1: train loss 0.0084, accuracy 0.8022\n",
            "\u001b[36m(ClientAppActor pid=84643)\u001b[0m [Client 1] fit, config: {}\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=84645)\u001b[0m Epoch 1: train loss 0.0093, accuracy 0.7530\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=84645)\u001b[0m [Client 2] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 4 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 7]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=84645)\u001b[0m [Client 2] fit, config: {}\n",
            "\u001b[36m(ClientAppActor pid=84646)\u001b[0m [Client 0] evaluate, config: {}\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=84645)\u001b[0m Epoch 1: train loss 0.0079, accuracy 0.8070\n",
            "\u001b[36m(ClientAppActor pid=84643)\u001b[0m [Client 3] fit, config: {}\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=84643)\u001b[0m Epoch 1: train loss 0.0083, accuracy 0.7845\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=84643)\u001b[0m [Client 3] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 4 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 8]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=84645)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[36m(ClientAppActor pid=84646)\u001b[0m [Client 2] evaluate, config: {}\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=84646)\u001b[0m Epoch 1: train loss 0.0071, accuracy 0.8228\n",
            "\u001b[36m(ClientAppActor pid=84643)\u001b[0m [Client 2] fit, config: {}\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=84644)\u001b[0m [Client 2] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 4 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 9]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=84644)\u001b[0m Epoch 1: train loss 0.0082, accuracy 0.8099\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=84645)\u001b[0m [Client 1] fit, config: {}\n",
            "\u001b[36m(ClientAppActor pid=84643)\u001b[0m [Client 3] evaluate, config: {}\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=84644)\u001b[0m [Client 3] fit, config: {}\n",
            "\u001b[36m(ClientAppActor pid=84646)\u001b[0m Epoch 1: train loss 0.0065, accuracy 0.8471\n",
            "\u001b[36m(ClientAppActor pid=84643)\u001b[0m [Client 0] fit, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=84645)\u001b[0m Epoch 1: train loss 0.0063, accuracy 0.8519\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=84644)\u001b[0m Epoch 1: train loss 0.0070, accuracy 0.8354\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=84645)\u001b[0m [Client 1] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 4 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 10]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=84645)\u001b[0m [Client 2] fit, config: {}\n",
            "\u001b[36m(ClientAppActor pid=84643)\u001b[0m [Client 2] evaluate, config: {}\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=84645)\u001b[0m Epoch 1: train loss 0.0058, accuracy 0.8495\n",
            "\u001b[36m(ClientAppActor pid=84643)\u001b[0m [Client 3] fit, config: {}\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=84643)\u001b[0m Epoch 1: train loss 0.0057, accuracy 0.8559\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=84645)\u001b[0m [Client 2] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 4 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [SUMMARY]\n",
            "\u001b[92mINFO \u001b[0m:      Run finished 10 round(s) in 1471.49s\n",
            "\u001b[92mINFO \u001b[0m:      \tHistory (loss, distributed):\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 1: 0.02477520655144702\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 2: 0.017717666187129177\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 3: 0.015574441015065372\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 4: 0.015595822462013789\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 5: 0.013922583025235396\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 6: 0.012446176301647018\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 7: 0.012794342178564806\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 8: 0.011842850472900894\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 9: 0.012195389021883954\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 10: 0.012287225205819685\n",
            "\u001b[92mINFO \u001b[0m:      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final parameters could not be extracted from the results.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Accuracy Data\n",
        "rounds = list(range(1, 11))\n",
        "accuracy_resnet50 = [69.42, 75.73, 78.52, 79.49, 81.19, 81.55, 81.92, 83.25, 84.47, 85.11]\n",
        "accuracy_mobilenetv2 = [66.50, 73.54, 76.82, 80.83, 81.92, 82.89, 83.92, 84.83, 85.32, 87.86]\n",
        "accuracy_squeezenet = [65.05, 73.54, 74.51, 72.52, 74.64, 80.22, 80.70, 82.28, 85.19, 85.59]\n",
        "accuracy_shufflenet = [65.05, 73.54, 74.51, 72.52, 74.64, 80.22, 80.70, 82.28, 85.19, 85.59]\n",
        "\n",
        "# Loss Data\n",
        "loss_resnet50 = [0.8522, 0.7069, 0.6278, 0.5662, 0.5171, 0.4745, 0.4777, 0.4632, 0.4196, 0.3858]\n",
        "loss_mobilenetv2 = [0.0135, 0.0111, 0.0100, 0.0084, 0.0077, 0.0075, 0.0074, 0.0062, 0.0057, 0.0052]\n",
        "loss_squeezenet = [0.0248, 0.0144, 0.0153, 0.0156, 0.0139, 0.0124, 0.0128, 0.0118, 0.0122, 0.0123]\n",
        "loss_shufflenet = [0.0216, 0.0144, 0.0153, 0.0156, 0.0139, 0.0124, 0.0128, 0.0118, 0.0122, 0.0123]\n",
        "\n",
        "# Plotting Accuracy\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(rounds, accuracy_resnet50, label='ResNet50', marker='o')\n",
        "plt.plot(rounds, accuracy_mobilenetv2, label='MobileNetV2', marker='o')\n",
        "plt.plot(rounds, accuracy_squeezenet, label='SqueezeNet', marker='o')\n",
        "plt.plot(rounds, accuracy_shufflenet, label='ShuffleNet', marker='o')\n",
        "plt.xlabel('Rounds')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.title('Model Accuracy Over Training Rounds')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# Plotting Loss\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(rounds, loss_resnet50, label='ResNet50', marker='o')\n",
        "plt.plot(rounds, loss_mobilenetv2, label='MobileNetV2', marker='o')\n",
        "plt.plot(rounds, loss_squeezenet, label='SqueezeNet', marker='o')\n",
        "plt.plot(rounds, loss_shufflenet, label='ShuffleNet', marker='o')\n",
        "plt.xlabel('Rounds')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Model Loss Over Training Rounds')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "MilKoyEgdfOt",
        "outputId": "050306a0-040c-4bb0-929b-80e4f66344b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IaEJ2721cMn4"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}